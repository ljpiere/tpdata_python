{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f380ec5a",
   "metadata": {},
   "source": [
    "# Sprint 8 · Webinar 24 · Data Analytics práctico (Repaso: funciones, ciclos y setup en VS Code)\n",
    "\n",
    "**Duración:** 100 minutos  \n",
    "**Modalidad:** Práctica guiada (mini-proyecto paso a paso)  \n",
    "\n",
    "En esta sesión haremos un **repaso práctico** de:\n",
    "- **Funciones en Python** aplicadas a tareas típicas de analítica con **pandas**\n",
    "- **Bucles `for` y `while`** (ciclos) y control de flujo\n",
    "- **Uso de VS Code** + instalación de **Python global** (sin entornos virtuales), con una explicación conceptual de qué es un entorno virtual y por qué suele usarse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a31a83",
   "metadata": {},
   "source": [
    "## Fecha\n",
    "\n",
    "Completa la información de la sesión:\n",
    "\n",
    "- **Fecha:**  \n",
    "- **Instructor/a:**  \n",
    "- **Duración:** 100 minutos  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2df147",
   "metadata": {},
   "source": [
    "## Objetivos de la sesión práctica\n",
    "\n",
    "Al finalizar esta sesión, el/la estudiante podrá:\n",
    "\n",
    "1. **Instalar y verificar Python** en Windows usando una instalación global, y configurar **VS Code** para trabajar con Python y Jupyter.\n",
    "2. **Cargar y explorar** un dataset con `pandas` (EDA rápido orientado a negocio).\n",
    "3. **Escribir funciones** reutilizables para limpieza, creación de variables y cálculo de KPIs.\n",
    "4. **Aplicar bucles `for`** para automatizar cálculos repetitivos y construir reportes.\n",
    "5. **Aplicar bucles `while`** en escenarios controlados (iteraciones con condición de parada) y reconocer cuándo es mejor preferir operaciones vectorizadas de pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno (VS Code + Python + librerías)\n",
    "\n",
    "Esta sesión asume una **instalación global** de Python (sin entornos virtuales). Aun así, al final verás una explicación corta de qué es un entorno virtual y cuándo conviene usarlo.\n",
    "\n",
    "### 1) Instalar Python (instalación global)\n",
    "\n",
    "**Windows (recomendado para clase):**\n",
    "1. Descarga Python desde el sitio oficial (python.org) e inicia el instalador.\n",
    "2. En la primera pantalla marca:\n",
    "   - **Add python.exe to PATH**\n",
    "   - (Opcional) **Install launcher for all users**\n",
    "3. Completa la instalación.\n",
    "\n",
    "**Verifica en una terminal (PowerShell / CMD):**\n",
    "- `python --version`\n",
    "- `python -m pip --version`\n",
    "\n",
    "> Si en Windows tu comando `python` no funciona, prueba con `py -V` y usa `py -m pip ...` para instalar paquetes.\n",
    "\n",
    "### 2) Instalar VS Code\n",
    "\n",
    "1. Descarga e instala Visual Studio Code desde el sitio oficial.\n",
    "2. Abre VS Code y (si aplica) habilita el comando `code` en el PATH (en Windows suele configurarse automáticamente).\n",
    "\n",
    "### 3) Extensiones necesarias en VS Code\n",
    "\n",
    "Instala estas extensiones (panel de Extensions):\n",
    "- **Python** (Microsoft)\n",
    "- **Jupyter** (Microsoft)\n",
    "\n",
    "Opcional (pero útil):\n",
    "- **Pylance** (autocompletado y análisis estático)\n",
    "\n",
    "### 4) Abrir el proyecto en VS Code\n",
    "\n",
    "1. Crea una carpeta (por ejemplo: `sprint8_webinar24/`).\n",
    "2. Guarda dentro:\n",
    "   - Este notebook `Sprint8_Webinar24_Practico.ipynb`\n",
    "   - El dataset `sprint8_webinar24_dataset.csv`\n",
    "3. En VS Code: **File → Open Folder...** y selecciona la carpeta.\n",
    "\n",
    "### 5) Seleccionar intérprete y kernel\n",
    "\n",
    "1. `Ctrl + Shift + P` → **Python: Select Interpreter** → elige tu Python instalado.\n",
    "2. Abre el notebook → arriba a la derecha: **Select Kernel** → elige el mismo intérprete.\n",
    "\n",
    "### 6) Instalar librerías (global) con `pip`\n",
    "\n",
    "Ejecuta en la terminal **del sistema** (no dentro del notebook):\n",
    "\n",
    "- Actualizar `pip`:\n",
    "  - `python -m pip install --upgrade pip`\n",
    "\n",
    "- Instalar librerías para analítica:\n",
    "  - `python -m pip install numpy pandas scipy matplotlib`\n",
    "\n",
    "> En Windows con launcher:\n",
    "> - `py -m pip install --upgrade pip`\n",
    "> - `py -m pip install numpy pandas scipy matplotlib`\n",
    "\n",
    "### 7) ¿Qué es un entorno virtual? (teoría rápida)\n",
    "\n",
    "Un **entorno virtual** (por ejemplo, `venv`) es una “copia aislada” de Python para un proyecto. Sirve para:\n",
    "- Evitar conflictos de versiones entre proyectos.\n",
    "- Reproducir el mismo entorno en otra máquina.\n",
    "- Mantener dependencias del proyecto separadas del sistema.\n",
    "\n",
    "En esta clase **no lo usamos** para reducir fricción de instalación, pero es una buena práctica en proyectos reales.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Verificación rápida de instalación (ejecuta después de instalar paquetes)\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa596f",
   "metadata": {},
   "source": [
    "## Metodología de la sesión\n",
    "\n",
    "- Trabajaremos sobre un **dataset sintético** que generaremos en clase (y guardaremos como CSV).\n",
    "- El objetivo es replicar un flujo real de analítica:\n",
    "  1) Generación / carga de datos  \n",
    "  2) Revisión rápida de calidad  \n",
    "  3) Transformación (features)  \n",
    "  4) Métricas (KPIs)  \n",
    "  5) Automatización (funciones + ciclos)  \n",
    "- El código está pensado para estudiantes que están iniciando: incluye **comentarios**, **docstrings** y pasos graduales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65908e",
   "metadata": {},
   "source": [
    "## Agenda sugerida (100 minutos)\n",
    "\n",
    "| Tiempo | Bloque | Contenido | Output |\n",
    "|---:|---|---|---|\n",
    "| 10 min | Setup | Python global + VS Code (conceptos y verificación) | Entorno listo |\n",
    "| 10 min | Kickoff | Contexto del mini-proyecto + preguntas guía | Hipótesis iniciales |\n",
    "| 15 min | Datos | Generar CSV sintético + diccionario de datos | `data/retail_pulse_transactions.csv` |\n",
    "| 15 min | EDA rápido | Calidad + exploración inicial | Checklist de calidad |\n",
    "| 20 min | Repaso funciones | Limpieza + features + KPIs con funciones | Pipeline simple |\n",
    "| 20 min | Repaso ciclos | `for` y `while` aplicados a reportes | Reporte mensual / validación iterativa |\n",
    "| 10 min | Cierre | Takeaways + siguientes pasos | Próxima práctica |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eae96f",
   "metadata": {},
   "source": [
    "## Ejercicio 0 · Kickoff del mini-proyecto (10 min)\n",
    "\n",
    "### Contexto\n",
    "Eres analista en una empresa de retail que vende por **tienda** y **canal online**. El área comercial quiere entender:\n",
    "\n",
    "- ¿Cómo evolucionan las ventas por mes?\n",
    "- ¿Qué categorías y canales generan más ingresos?\n",
    "- ¿Hay señales de fricción logística (tiempos de entrega altos, devoluciones)?\n",
    "\n",
    "### Preguntas guía (discusión rápida)\n",
    "1. ¿Qué métrica usarías como “ventas”? (pista: ingreso = unidades × precio × (1 - descuento))\n",
    "2. ¿Qué variables podrían influir en devoluciones?\n",
    "3. ¿Qué KPI usarías para monitorear “experiencia del cliente” con datos limitados?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a744f87",
   "metadata": {},
   "source": [
    "## Proyecto práctico: “Retail Pulse” (Sales Analytics)\n",
    "\n",
    "En este mini-proyecto construiremos un pipeline básico de analítica con pandas:\n",
    "\n",
    "1. Generamos un dataset sintético de transacciones (CSV).\n",
    "2. Hacemos EDA rápido y verificaciones de calidad.\n",
    "3. Definimos funciones para limpieza, enriquecimiento (features) y KPIs.\n",
    "4. Automatizamos reportes con ciclos (`for`, `while`) y comparamos con alternativas vectorizadas en pandas.\n",
    "\n",
    "### Entregables del proyecto (lo que deberías poder entregar al final)\n",
    "- Un archivo CSV en `data/retail_pulse_transactions.csv`\n",
    "- Un DataFrame listo para análisis con:\n",
    "  - `revenue`, `month`, `is_weekend`, etc.\n",
    "- Un reporte mensual de KPIs (tabla)\n",
    "- 3–5 insights escritos (en un markdown al final del notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a0e58c",
   "metadata": {},
   "source": [
    "## Diccionario de datos (CSV)\n",
    "\n",
    "Cada fila representa una **transacción** (compra).\n",
    "\n",
    "| Columna | Tipo | Descripción |\n",
    "|---|---|---|\n",
    "| `transaction_id` | int | Identificador de la transacción |\n",
    "| `date` | datetime | Fecha de la compra |\n",
    "| `customer_id` | int | Identificador del cliente |\n",
    "| `region` | category | Región (Norte, Centro, Sur) |\n",
    "| `channel` | category | Canal (Store / Online) |\n",
    "| `category` | category | Categoría de producto |\n",
    "| `product_id` | int | Identificador del producto |\n",
    "| `units` | int | Unidades compradas |\n",
    "| `unit_price` | float | Precio por unidad |\n",
    "| `discount_pct` | float | Descuento (0 a 0.30) |\n",
    "| `payment_method` | category | Método de pago |\n",
    "| `delivery_days` | int | Días de entrega (solo Online; Store=0) |\n",
    "| `returned` | bool | Si la compra fue devuelta |\n",
    "| `satisfaction_score` | float | Calificación de satisfacción (0–10, puede tener nulos) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98783642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup básico: imports y configuración\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Opciones visuales (para ver más columnas al hacer print)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f4020",
   "metadata": {},
   "source": [
    "## Ejercicio 1 · Generar el dataset sintético (15 min)\n",
    "\n",
    "Generaremos un dataset con transacciones de los últimos 12 meses.\n",
    "- Incluiremos algunas *imperfecciones realistas*: nulos en satisfacción y algunos valores atípicos en `delivery_days`.\n",
    "- Guardaremos el resultado como CSV en la carpeta `data/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Parámetros de generación (puedes ajustar N para más/menos datos)\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "N = 12000  # número de transacciones\n",
    "start_date = pd.Timestamp.today().normalize() - pd.Timedelta(days=365)\n",
    "\n",
    "# 2) Catálogos simples\n",
    "regions = [\"Norte\", \"Centro\", \"Sur\"]\n",
    "channels = [\"Store\", \"Online\"]\n",
    "categories = [\"Grocery\", \"Electronics\", \"Home\", \"Beauty\", \"Sports\"]\n",
    "payment_methods = [\"Card\", \"Cash\", \"Transfer\", \"Wallet\"]\n",
    "\n",
    "# 3) Generar columnas base\n",
    "dates = start_date + pd.to_timedelta(rng.integers(0, 365, size=N), unit=\"D\")\n",
    "customer_id = rng.integers(1000, 2500, size=N)\n",
    "region = rng.choice(regions, size=N, p=[0.30, 0.45, 0.25])\n",
    "channel = rng.choice(channels, size=N, p=[0.55, 0.45])\n",
    "category = rng.choice(categories, size=N, p=[0.35, 0.15, 0.20, 0.15, 0.15])\n",
    "\n",
    "# Simular productos: 50 productos por categoría\n",
    "product_id = (\n",
    "    pd.Series(category)\n",
    "    .map({cat: i for i, cat in enumerate(categories)})\n",
    "    .to_numpy() * 1000\n",
    "    + rng.integers(1, 51, size=N)\n",
    ")\n",
    "\n",
    "units = rng.integers(1, 6, size=N)  # 1 a 5 unidades\n",
    "base_price = rng.normal(loc=40, scale=18, size=N).clip(5, 200)  # precio base\n",
    "# Ajuste por categoría (electrónica más cara)\n",
    "cat_multiplier = pd.Series(category).map(\n",
    "    {\"Grocery\": 0.7, \"Electronics\": 1.8, \"Home\": 1.1, \"Beauty\": 0.9, \"Sports\": 1.2}\n",
    ").to_numpy()\n",
    "unit_price = (base_price * cat_multiplier).round(2)\n",
    "\n",
    "discount_pct = rng.choice([0, 0.05, 0.10, 0.15, 0.20, 0.30], size=N, p=[0.45, 0.15, 0.15, 0.12, 0.10, 0.03])\n",
    "\n",
    "payment_method = rng.choice(payment_methods, size=N, p=[0.55, 0.18, 0.12, 0.15])\n",
    "\n",
    "# Delivery days: solo online, store = 0\n",
    "delivery_days = np.where(\n",
    "    channel == \"Online\",\n",
    "    rng.integers(1, 8, size=N),  # 1 a 7\n",
    "    0\n",
    ")\n",
    "\n",
    "# Insertar algunos valores atípicos en delivery (online)\n",
    "outlier_idx = rng.choice(np.where(channel == \"Online\")[0], size=60, replace=False)\n",
    "delivery_days[outlier_idx] = rng.integers(15, 40, size=60)  # outliers\n",
    "\n",
    "# Returned: mayor probabilidad si delivery es alto y en electronics\n",
    "returned_prob = (\n",
    "    0.04\n",
    "    + 0.02 * (channel == \"Online\")\n",
    "    + 0.03 * (delivery_days >= 10)\n",
    "    + 0.02 * (category == \"Electronics\")\n",
    ")\n",
    "returned = rng.random(size=N) < returned_prob\n",
    "\n",
    "# Satisfaction: base alta, se reduce con delivery alto y devoluciones, con nulos\n",
    "satisfaction = (\n",
    "    rng.normal(loc=8.2, scale=1.2, size=N)\n",
    "    - 0.10 * delivery_days\n",
    "    - 1.2 * returned.astype(int)\n",
    ").clip(0, 10)\n",
    "\n",
    "# Insertar nulos (faltantes) en satisfacción (~8%)\n",
    "mask_null = rng.random(size=N) < 0.08\n",
    "satisfaction = satisfaction.astype(float)\n",
    "satisfaction[mask_null] = np.nan\n",
    "\n",
    "df_raw = pd.DataFrame({\n",
    "    \"transaction_id\": np.arange(1, N + 1),\n",
    "    \"date\": dates,\n",
    "    \"customer_id\": customer_id,\n",
    "    \"region\": region,\n",
    "    \"channel\": channel,\n",
    "    \"category\": category,\n",
    "    \"product_id\": product_id,\n",
    "    \"units\": units,\n",
    "    \"unit_price\": unit_price,\n",
    "    \"discount_pct\": discount_pct,\n",
    "    \"payment_method\": payment_method,\n",
    "    \"delivery_days\": delivery_days,\n",
    "    \"returned\": returned,\n",
    "    \"satisfaction_score\": satisfaction.round(1),\n",
    "})\n",
    "\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c85847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar CSV\n",
    "csv_path = DATA_DIR / \"retail_pulse_transactions.csv\"\n",
    "df_raw.to_csv(csv_path, index=False)\n",
    "\n",
    "csv_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a5609",
   "metadata": {},
   "source": [
    "## Ejercicio 2 · Cargar el CSV y revisar calidad de datos (EDA rápido) (15 min)\n",
    "\n",
    "Checklist mínimo:\n",
    "- ¿Cuántas filas y columnas tenemos?\n",
    "- Tipos de datos (`dtypes`)\n",
    "- Nulos por columna\n",
    "- Duplicados\n",
    "- Rangos esperados (ej. `discount_pct` entre 0 y 0.30, `units` >= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, parse_dates=[\"date\"])\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "display(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nulos por columna\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "display((missing * 100).round(2).to_frame(\"missing_%\"))\n",
    "\n",
    "# Duplicados de transacción\n",
    "dup_count = df.duplicated(subset=[\"transaction_id\"]).sum()\n",
    "print(\"Duplicados en transaction_id:\", dup_count)\n",
    "\n",
    "# Validaciones rápidas de rangos\n",
    "print(\"discount_pct min/max:\", df[\"discount_pct\"].min(), df[\"discount_pct\"].max())\n",
    "print(\"units min/max:\", df[\"units\"].min(), df[\"units\"].max())\n",
    "print(\"delivery_days min/max:\", df[\"delivery_days\"].min(), df[\"delivery_days\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29f840",
   "metadata": {},
   "source": [
    "### Mini-ejercicio (5 min)\n",
    "\n",
    "1. Crea una columna `revenue_raw = units * unit_price` (sin descuento).  \n",
    "2. ¿Qué porcentaje de transacciones son `Online`?  \n",
    "3. ¿Cuál es la categoría con mayor revenue promedio (sin descuento)?\n",
    "\n",
    "> Responde con código. Luego revisa la solución.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6176b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) revenue_raw\n",
    "df[\"revenue_raw\"] = df[\"units\"] * df[\"unit_price\"]\n",
    "\n",
    "# 2) porcentaje online\n",
    "pct_online = (df[\"channel\"].eq(\"Online\").mean() * 100).round(2)\n",
    "\n",
    "# 3) categoría con mayor revenue promedio\n",
    "top_cat = (\n",
    "    df.groupby(\"category\")[\"revenue_raw\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "print(\"Online %:\", pct_online)\n",
    "display(top_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a270006",
   "metadata": {},
   "source": [
    "## Repaso · Funciones en Python para analítica con pandas (20 min)\n",
    "\n",
    "### Idea clave\n",
    "En analítica, las funciones ayudan a:\n",
    "- Reutilizar lógica (limpieza, features, métricas)\n",
    "- Reducir errores por copiar/pegar\n",
    "- Documentar el propósito de cada bloque de transformación\n",
    "\n",
    "En este ejercicio construiremos un mini **pipeline** con 3 funciones:\n",
    "1. `clean_transactions(df)`  \n",
    "2. `add_features(df)`  \n",
    "3. `compute_kpis(df)`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transactions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Limpia el dataset de transacciones.\n",
    "\n",
    "    Acciones:\n",
    "    - Asegura tipos básicos.\n",
    "    - Imputa satisfacción faltante con la mediana por canal.\n",
    "    - Crea una columna booleana de 'is_online' para facilitar análisis.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original con transacciones.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copia limpia (no modifica el df original).\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Tipos: (en proyectos reales, esto suele venir de un diccionario de datos)\n",
    "    out[\"region\"] = out[\"region\"].astype(\"category\")\n",
    "    out[\"channel\"] = out[\"channel\"].astype(\"category\")\n",
    "    out[\"category\"] = out[\"category\"].astype(\"category\")\n",
    "    out[\"payment_method\"] = out[\"payment_method\"].astype(\"category\")\n",
    "\n",
    "    # Imputación simple: mediana de satisfacción por canal\n",
    "    median_by_channel = out.groupby(\"channel\")[\"satisfaction_score\"].median()\n",
    "    out[\"satisfaction_score\"] = out[\"satisfaction_score\"].fillna(out[\"channel\"].map(median_by_channel))\n",
    "\n",
    "    out[\"is_online\"] = out[\"channel\"].eq(\"Online\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agrega variables (features) útiles para análisis.\n",
    "\n",
    "    Features:\n",
    "    - month (periodo mensual)\n",
    "    - revenue (aplicando descuento)\n",
    "    - is_weekend\n",
    "    - delayed_delivery (online con delivery >= 7)\n",
    "\n",
    "    Retorna una copia del DataFrame.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"month\"] = out[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "    out[\"revenue\"] = out[\"units\"] * out[\"unit_price\"] * (1 - out[\"discount_pct\"])\n",
    "    out[\"is_weekend\"] = out[\"date\"].dt.dayofweek >= 5\n",
    "\n",
    "    out[\"delayed_delivery\"] = out[\"is_online\"] & (out[\"delivery_days\"] >= 7)\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_kpis(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calcula KPIs agregados por mes.\n",
    "\n",
    "    KPIs:\n",
    "    - revenue_total\n",
    "    - orders\n",
    "    - avg_revenue_per_order\n",
    "    - return_rate\n",
    "    - avg_delivery_days_online\n",
    "    - avg_satisfaction\n",
    "\n",
    "    Retorna un DataFrame con una fila por mes.\n",
    "    \"\"\"\n",
    "    # Nota: usamos df ya con features\n",
    "    g = df.groupby(\"month\")\n",
    "\n",
    "    kpis = pd.DataFrame({\n",
    "        \"revenue_total\": g[\"revenue\"].sum(),\n",
    "        \"orders\": g[\"transaction_id\"].nunique(),\n",
    "        \"avg_revenue_per_order\": g[\"revenue\"].mean(),\n",
    "        \"return_rate\": g[\"returned\"].mean(),\n",
    "        \"avg_delivery_days_online\": g.apply(lambda x: x.loc[x[\"is_online\"], \"delivery_days\"].mean()),\n",
    "        \"avg_satisfaction\": g[\"satisfaction_score\"].mean(),\n",
    "    }).reset_index()\n",
    "\n",
    "    # Orden cronológico por month (YYYY-MM)\n",
    "    kpis = kpis.sort_values(\"month\")\n",
    "    return kpis\n",
    "\n",
    "\n",
    "df_clean = clean_transactions(df)\n",
    "df_feat = add_features(df_clean)\n",
    "kpis_month = compute_kpis(df_feat)\n",
    "\n",
    "display(kpis_month.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe4fb9c",
   "metadata": {},
   "source": [
    "### Mini-ejercicio (5 min)\n",
    "\n",
    "Crea una función `top_categories(df, n=3)` que retorne las `n` categorías con mayor revenue total.\n",
    "\n",
    "Pista: `groupby(\"category\")[\"revenue\"].sum()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12979fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_categories(df: pd.DataFrame, n: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Retorna las n categorías con mayor revenue total.\"\"\"\n",
    "    out = (\n",
    "        df.groupby(\"category\")[\"revenue\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(n)\n",
    "        .to_frame(\"revenue_total\")\n",
    "    )\n",
    "    return out\n",
    "\n",
    "display(top_categories(df_feat, n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec53f4d",
   "metadata": {},
   "source": [
    "## Repaso · Bucles `for` (20 min)\n",
    "\n",
    "### ¿Para qué usar `for` en analítica?\n",
    "- Construir reportes por particiones (mes, región, categoría)\n",
    "- Ejecutar validaciones repetitivas\n",
    "- Aplicar una misma lógica a una lista de variables\n",
    "\n",
    "**Nota importante:** en pandas, muchas tareas se resuelven mejor con `groupby`, `agg`, `merge` y operaciones vectorizadas.  \n",
    "Aun así, entender `for` es esencial para automatizar y para leer código de otros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ccbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte mensual por región usando un bucle for\n",
    "months = sorted(df_feat[\"month\"].unique())\n",
    "\n",
    "rows = []\n",
    "for m in months:\n",
    "    df_m = df_feat[df_feat[\"month\"] == m]\n",
    "\n",
    "    # KPIs por región (revenue y tasa de devoluciones)\n",
    "    by_region = df_m.groupby(\"region\").agg(\n",
    "        revenue_total=(\"revenue\", \"sum\"),\n",
    "        orders=(\"transaction_id\", \"nunique\"),\n",
    "        return_rate=(\"returned\", \"mean\"),\n",
    "    )\n",
    "\n",
    "    # Convertimos a formato \"largo\" para apilar resultados\n",
    "    by_region = by_region.reset_index()\n",
    "    by_region[\"month\"] = m\n",
    "    rows.append(by_region)\n",
    "\n",
    "report_region_month = pd.concat(rows, ignore_index=True).sort_values([\"month\", \"region\"])\n",
    "\n",
    "display(report_region_month.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativa (preferida en pandas): groupby sin bucle for\n",
    "report_region_month_fast = (\n",
    "    df_feat.groupby([\"month\", \"region\"])\n",
    "    .agg(\n",
    "        revenue_total=(\"revenue\", \"sum\"),\n",
    "        orders=(\"transaction_id\", \"nunique\"),\n",
    "        return_rate=(\"returned\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"month\", \"region\"])\n",
    ")\n",
    "\n",
    "# Validamos que ambas tablas coinciden en valores (mismo orden de columnas)\n",
    "check = report_region_month.merge(\n",
    "    report_region_month_fast,\n",
    "    on=[\"month\", \"region\"],\n",
    "    suffixes=(\"_for\", \"_pandas\")\n",
    ")\n",
    "\n",
    "# Diferencias absolutas (deberían ser ~0, salvo precisión flotante)\n",
    "check[\"diff_revenue\"] = (check[\"revenue_total_for\"] - check[\"revenue_total_pandas\"]).abs()\n",
    "check[\"diff_return_rate\"] = (check[\"return_rate_for\"] - check[\"return_rate_pandas\"]).abs()\n",
    "\n",
    "display(check[[\"month\",\"region\",\"diff_revenue\",\"diff_return_rate\"]].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e51d65",
   "metadata": {},
   "source": [
    "### Mini-ejercicio (5 min)\n",
    "\n",
    "Usa un `for` para construir una lista de resultados que contenga, por cada `category`, el `avg_satisfaction`.\n",
    "\n",
    "Output esperado: un DataFrame con columnas `category` y `avg_satisfaction`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for cat in sorted(df_feat[\"category\"].unique()):\n",
    "    avg_sat = df_feat.loc[df_feat[\"category\"] == cat, \"satisfaction_score\"].mean()\n",
    "    results.append({\"category\": cat, \"avg_satisfaction\": avg_sat})\n",
    "\n",
    "df_avg_sat = pd.DataFrame(results).sort_values(\"avg_satisfaction\", ascending=False)\n",
    "display(df_avg_sat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3e7dd",
   "metadata": {},
   "source": [
    "## Repaso · Bucles `while` (20 min)\n",
    "\n",
    "### ¿Cuándo usar `while`?\n",
    "`while` se usa cuando:\n",
    "- No sabes cuántas iteraciones necesitas de antemano.\n",
    "- Repites un proceso **hasta cumplir una condición** (con una condición de parada clara).\n",
    "\n",
    "Ejemplo en analítica:\n",
    "- Repetir una regla de *capping* de outliers hasta que el número de outliers se estabilice (con un máximo de iteraciones).\n",
    "\n",
    "> En proyectos reales debes ser cuidadoso: un `while` mal definido puede quedarse en un ciclo infinito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_delivery_outliers_iqr(df: pd.DataFrame) -> int:\n",
    "    \"\"\"Cuenta outliers en delivery_days (solo online) usando IQR.\"\"\"\n",
    "    x = df.loc[df[\"is_online\"], \"delivery_days\"].dropna()\n",
    "    q1, q3 = x.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return int(((x < lower) | (x > upper)).sum())\n",
    "\n",
    "\n",
    "def cap_delivery_outliers_iqr(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aplica capping (winsorization) a delivery_days (solo online) usando límites IQR.\"\"\"\n",
    "    out = df.copy()\n",
    "    mask = out[\"is_online\"]\n",
    "\n",
    "    x = out.loc[mask, \"delivery_days\"].dropna()\n",
    "    q1, q3 = x.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "\n",
    "    out.loc[mask, \"delivery_days\"] = out.loc[mask, \"delivery_days\"].clip(lower, upper)\n",
    "    return out\n",
    "\n",
    "\n",
    "# While: repetimos el capping hasta que no haya outliers (o hasta max_iter)\n",
    "df_loop = df_feat.copy()\n",
    "max_iter = 5\n",
    "iter_count = 0\n",
    "\n",
    "outliers = count_delivery_outliers_iqr(df_loop)\n",
    "print(\"Outliers iniciales (delivery_days, online):\", outliers)\n",
    "\n",
    "while (outliers > 0) and (iter_count < max_iter):\n",
    "    df_loop = cap_delivery_outliers_iqr(df_loop)\n",
    "    outliers = count_delivery_outliers_iqr(df_loop)\n",
    "    iter_count += 1\n",
    "    print(f\"Iteración {iter_count}: outliers = {outliers}\")\n",
    "\n",
    "print(\"Iteraciones ejecutadas:\", iter_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6de5c",
   "metadata": {},
   "source": [
    "### Nota\n",
    "Este ejemplo es didáctico: muchas veces **una sola** aplicación del capping es suficiente.  \n",
    "El objetivo es practicar la estructura del `while` y definir una **condición de parada** (por ejemplo `max_iter`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199416f",
   "metadata": {},
   "source": [
    "## VS Code + Python global (sin entornos virtuales)\n",
    "\n",
    "### 1) Instalación global de Python (Windows)\n",
    "1. Descarga Python desde el sitio oficial (recomendado) e instálalo.\n",
    "2. En el instalador, marca:\n",
    "   - **Add Python to PATH**\n",
    "   - **pip**\n",
    "3. Verifica en terminal (PowerShell o CMD):\n",
    "   - `python --version`\n",
    "   - `pip --version`\n",
    "\n",
    "> Si `python` no funciona pero `py` sí, puedes usar el launcher de Windows: `py -V`.\n",
    "\n",
    "### 2) VS Code: extensiones recomendadas\n",
    "- **Python** (Microsoft)\n",
    "- **Jupyter** (Microsoft)\n",
    "\n",
    "### 3) Seleccionar el intérprete\n",
    "En VS Code:\n",
    "- `Ctrl + Shift + P` → **Python: Select Interpreter**  \n",
    "- Elige el Python instalado globalmente (ej. Python 3.12/3.13).\n",
    "\n",
    "### 4) Ejecutar tu primer script\n",
    "Crea un archivo `hello.py`:\n",
    "\n",
    "```python\n",
    "print(\"Hola, mundo\")\n",
    "```\n",
    "\n",
    "En terminal:\n",
    "- `python hello.py`\n",
    "\n",
    "### 5) Trabajar con notebooks (`.ipynb`)\n",
    "- Abre un `.ipynb` con VS Code.\n",
    "- Selecciona el kernel (Python global).\n",
    "- Ejecuta celdas y revisa outputs.\n",
    "\n",
    "> Recomendación: si algo falla con Jupyter, instala (globalmente) estas dependencias:\n",
    "> - `pip install jupyter pandas numpy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d666e5",
   "metadata": {},
   "source": [
    "## ¿Qué es un entorno virtual (venv) y por qué existe? (conceptual)\n",
    "\n",
    "Un **entorno virtual** es una “copia aislada” del entorno de Python para un proyecto.\n",
    "\n",
    "### ¿Qué problema resuelve?\n",
    "- Dos proyectos pueden requerir **versiones distintas** de librerías (por ejemplo, `pandas==1.5` vs `pandas==2.2`).\n",
    "- Si instalas todo globalmente, puedes terminar con conflictos y errores difíciles de depurar.\n",
    "\n",
    "### ¿Cuándo te conviene usarlo?\n",
    "- Proyectos reales con dependencias específicas\n",
    "- Cuando compartes tu código con otras personas (reproducibilidad)\n",
    "- Cuando trabajas con varias versiones de Python/librerías\n",
    "\n",
    "En este webinar NO lo vamos a usar para mantener el flujo simple, pero es importante conocer el concepto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307bf394",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "- Las **funciones** permiten estructurar un pipeline analítico reutilizable.\n",
    "- Los ciclos (`for`, `while`) sirven para automatizar tareas repetitivas, pero en pandas muchas veces es mejor usar `groupby` y operaciones vectorizadas.\n",
    "- VS Code + Python global es una forma rápida de empezar; para proyectos más serios, los **entornos virtuales** mejoran la reproducibilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1355d59",
   "metadata": {},
   "source": [
    "## Cierre\n",
    "\n",
    "### Checklist de salida\n",
    "- [ ] Generé el CSV en `data/retail_pulse_transactions.csv`\n",
    "- [ ] Cargué y validé calidad (nulos, duplicados, rangos)\n",
    "- [ ] Construí funciones de limpieza, features y KPIs\n",
    "- [ ] Generé un reporte mensual por región (con `for` y con `groupby`)\n",
    "- [ ] Practiqué un `while` con condición de parada\n",
    "\n",
    "### Pregunta final\n",
    "¿Qué parte te pareció más útil para tu día a día: funciones, `for`, o `while`? ¿Por qué?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e91222",
   "metadata": {},
   "source": [
    "## Siguientes Pasos\n",
    "\n",
    "1. Convierte este notebook en un pequeño proyecto:\n",
    "   - carpeta `data/`\n",
    "   - carpeta `notebooks/`\n",
    "   - `README.md` con objetivos y hallazgos\n",
    "2. Agrega 3–5 insights basados en:\n",
    "   - revenue por canal y categoría\n",
    "   - relación entre `delivery_days` y `returned`\n",
    "   - satisfacción por canal y devoluciones\n",
    "3. (Opcional) Crea 1–2 visualizaciones (línea mensual de revenue, barras por categoría).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}