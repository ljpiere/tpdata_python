{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "cells": [
  {
   "id": "49315d8a",
   "cell_type": "markdown",
   "source": "# Sprint 7 · Webinar 21 · Data Analytics teórico (Valores atípicos, segmentación y GitHub)\n\n**Programa:** Data Analytics  \n**Sprint:** 7  \n**Modalidad:** Teórica (con demostraciones en Python)  \n",
   "metadata": {}
  },
  {
   "id": "1e3faca2",
   "cell_type": "markdown",
   "source": "## Fecha\n\nCompleta la información de la sesión:\n\n- **Fecha:**  \n- **Instructor/a:**  \n- **Duración:** 100 minutos  \n",
   "metadata": {}
  },
  {
   "id": "fe6abb6c",
   "cell_type": "markdown",
   "source": "## Objetivos de la sesión teórica\n\nAl finalizar esta sesión, la persona estudiante será capaz de:\n\n1. **Identificar valores atípicos (outliers)** usando reglas estadísticas (IQR y Z-score).\n2. **Interpretar outliers en contexto** (errores, casos de negocio válidos, eventos raros) y aplicar estrategias de tratamiento (verificación, recorte, transformación, segmentación).\n3. **Crear segmentos de clientes** con sentencias `if/elif/else` y con `apply()` para reglas más flexibles.\n4. **Redactar un Statistical Summary** breve y orientado a negocio con resultados reproducibles.\n5. **Almacenar y compartir análisis** aplicando buenas prácticas de GitHub: repos, estructura de proyecto y workflow en Google Colab.\n",
   "metadata": {}
  },
  {
   "id": "cd9af1c9",
   "cell_type": "markdown",
   "source": "## Agenda sugerida (100 minutos)\n\n| Tiempo | Bloque | Contenido | Modalidad |\n|---:|---|---|---|\n| 0–10 min | Calentamiento | ¿Qué es un outlier y por qué importa? | Discusión |\n| 10–25 min | Dataset | Crear un dataset extenso y explorarlo | Demo + práctica guiada |\n| 25–45 min | 7.3.1 | Identificar outliers con reglas estadísticas (IQR, Z-score) | Demo + preguntas |\n| 45–55 min | 7.3.2 | Tratar outliers según el contexto (decisiones) | Discusión + demo |\n| 55–70 min | 7.3.3 | Segmentación con sentencias `if` | Demo + mini-ejercicio |\n| 70–80 min | 7.3.4 | Segmentación con `apply()` + funciones con `if` | Demo + mini-ejercicio |\n| 80–88 min | 7.3.5 | Redacción de un Statistical Summary | Ejemplo guiado |\n| 88–100 min | 7.4 | GitHub: conceptos, estructura y workflow con Colab | Guía práctica |\n",
   "metadata": {}
  },
  {
   "id": "073b8c42",
   "cell_type": "markdown",
   "source": "## Ejercicio 0 · Calentamiento en breakout rooms (discusión conceptual, 10 min)\n\n**Objetivo:** Alinear criterios sobre qué es un valor atípico y cómo decidir si se “corrige” o se “interpreta”.\n\n**Preguntas guía (discútanlas en equipo):**\n1. Piensa en una métrica típica de negocio (ventas, visitas, tiempos, reclamos). ¿Qué podría verse como “outlier” y por qué?\n2. ¿Un outlier siempre es “malo”? Da un ejemplo donde sea un **error** y otro donde sea un **caso real** (pero raro).\n3. ¿Qué riesgos tiene eliminar outliers sin pensar en el contexto?\n4. ¿Cómo documentarías una decisión de tratamiento de outliers para que otro analista la entienda?\n\n**Salida esperada:** 3–5 bullet points con conclusiones del equipo.\n",
   "metadata": {}
  },
  {
   "id": "81d75641",
   "cell_type": "markdown",
   "source": "## Ejercicio 1 · Crear y explorar un dataset extenso para análisis (15 min)\n\nEn esta sesión vamos a trabajar con un dataset **sintético** (generado por nosotros) que simula un escenario típico de analítica:\n\n- **Clientes** con atributos demográficos y de adquisición.\n- **Transacciones** (compras) con montos, descuentos y categorías.\n- Una tabla de **métricas por cliente** (agregadas) para análisis de outliers y segmentación.\n\n> En proyectos reales, el dataset vendría de una base de datos o un data warehouse. Aquí lo generamos para enfocarnos en los conceptos.\n\n### 1.1 Generación del dataset\n\nEl siguiente código crea:\n- `df_customers` (clientes)\n- `df_transactions` (transacciones)\n- `df_customer_metrics` (métricas agregadas por cliente)\n",
   "metadata": {}
  },
  {
   "id": "17ce2c9d",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 1) Setup del entorno\n# ============================================================\nimport numpy as np\nimport pandas as pd\n\n# Para reproducibilidad: si todas las personas usan la misma semilla,\n# obtendrán el mismo dataset y los mismos resultados.\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\n\npd.set_option('display.max_columns', 50)\n\n",
   "outputs": []
  },
  {
   "id": "cf68585f",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 2) Crear dataset sintético de clientes\n# ============================================================\nn_customers = 5000\n\ncustomer_id = np.arange(1, n_customers + 1)\n\nregions = ['Norte', 'Centro', 'Sur', 'Occidente', 'Oriente']\nchannels = ['Organic', 'Ads', 'Referral', 'Partners', 'Email']\nplans = ['Basic', 'Standard', 'Premium']\n\ndf_customers = pd.DataFrame({\n    'customer_id': customer_id,\n    'region': rng.choice(regions, size=n_customers, p=[0.18, 0.25, 0.22, 0.18, 0.17]),\n    'acquisition_channel': rng.choice(channels, size=n_customers, p=[0.35, 0.25, 0.15, 0.10, 0.15]),\n    'plan': rng.choice(plans, size=n_customers, p=[0.55, 0.35, 0.10]),\n})\n\n# Edad: normalmente 18–70, pero insertaremos algunos valores atípicos (errores o casos extremos)\nage = rng.normal(loc=38, scale=12, size=n_customers).round().astype(int)\nage = np.clip(age, 16, 85)\n\n# Insertar outliers de edad (pocos, para analizar)\noutlier_idx = rng.choice(n_customers, size=10, replace=False)\nage[outlier_idx[:5]] = rng.integers(1, 10, size=5)      # edades demasiado bajas (posible error)\nage[outlier_idx[5:]] = rng.integers(95, 120, size=5)    # edades demasiado altas (posible error)\n\ndf_customers['age'] = age\n\n# Fecha de registro (signup)\nstart_date = pd.Timestamp('2023-01-01')\nend_date = pd.Timestamp('2025-12-01')\nsignup_days = rng.integers(0, (end_date - start_date).days, size=n_customers)\ndf_customers['signup_date'] = start_date + pd.to_timedelta(signup_days, unit='D')\n\ndf_customers.head()\n",
   "outputs": []
  },
  {
   "id": "e6f36c50",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 3) Crear dataset sintético de transacciones\n# ============================================================\n# Generaremos transacciones por cliente con distribución sesgada (muchas compras pequeñas y pocas grandes)\nn_transactions = 120_000\n\ntransaction_id = np.arange(1, n_transactions + 1)\ncustomer_for_tx = rng.choice(df_customers['customer_id'], size=n_transactions, replace=True)\n\ncategories = ['Suscripción', 'Add-on', 'Soporte', 'Capacitación', 'Servicios Profesionales']\npayment_methods = ['Tarjeta', 'Transferencia', 'PSE', 'Efectivo', 'Billetera']\n\n# Monto base: distribución log-normal para simular \"cola larga\" en gasto\namount = rng.lognormal(mean=3.0, sigma=0.8, size=n_transactions)  # ~20–2000 en la mayoría de casos\n\n# Ajuste por plan: Premium tiende a tener tickets más altos\nplan_map = df_customers.set_index('customer_id')['plan'].to_dict()\nplan_factor = np.array([{'Basic': 0.9, 'Standard': 1.0, 'Premium': 1.3}[plan_map[c]] for c in customer_for_tx])\namount = amount * plan_factor\n\n# Descuento: la mayoría 0–20%, algunos más altos (promos)\ndiscount_pct = rng.choice([0, 5, 10, 15, 20, 30, 40, 50], size=n_transactions,\n                          p=[0.35, 0.12, 0.18, 0.13, 0.10, 0.07, 0.03, 0.02])\n\n# Fecha de transacción\ntx_start = pd.Timestamp('2024-01-01')\ntx_end = pd.Timestamp('2025-12-31')\ntx_days = rng.integers(0, (tx_end - tx_start).days + 1, size=n_transactions)\ntx_date = tx_start + pd.to_timedelta(tx_days, unit='D')\n\ndf_transactions = pd.DataFrame({\n    'transaction_id': transaction_id,\n    'customer_id': customer_for_tx,\n    'transaction_date': tx_date,\n    'category': rng.choice(categories, size=n_transactions, p=[0.55, 0.15, 0.15, 0.08, 0.07]),\n    'payment_method': rng.choice(payment_methods, size=n_transactions, p=[0.55, 0.18, 0.15, 0.05, 0.07]),\n    'amount_gross': amount.round(2),\n    'discount_pct': discount_pct\n})\n\n# Aplicar descuento: amount_net = amount_gross * (1 - discount_pct/100)\ndf_transactions['amount_net'] = (df_transactions['amount_gross'] * (1 - df_transactions['discount_pct'] / 100)).round(2)\n\n# Insertar outliers en montos: algunas transacciones extremadamente altas (casos raros o errores)\nhigh_outlier_rows = rng.choice(n_transactions, size=25, replace=False)\ndf_transactions.loc[high_outlier_rows, 'amount_gross'] = rng.uniform(20_000, 120_000, size=25).round(2)\ndf_transactions.loc[high_outlier_rows, 'amount_net'] = (df_transactions.loc[high_outlier_rows, 'amount_gross'] *\n                                                       (1 - df_transactions.loc[high_outlier_rows, 'discount_pct'] / 100)).round(2)\n\n# Insertar montos negativos: simulamos reembolsos (no necesariamente outliers, sino otro tipo de evento)\nrefund_rows = rng.choice(n_transactions, size=60, replace=False)\ndf_transactions.loc[refund_rows, 'amount_gross'] = -rng.uniform(10, 2000, size=60).round(2)\ndf_transactions.loc[refund_rows, 'amount_net'] = df_transactions.loc[refund_rows, 'amount_gross']\n\ndf_transactions.head()\n",
   "outputs": []
  },
  {
   "id": "f58c4cbd",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 4) Crear métricas por cliente (dataset de trabajo principal)\n# ============================================================\n# En analítica es muy común pasar de \"eventos\" (transacciones) a métricas agregadas por entidad (cliente).\n# Esto facilita: outlier detection, segmentación, dashboards, etc.\n\n# Fijamos una fecha de corte (como si fuera \"hoy\" para el análisis)\nanalysis_date = pd.Timestamp('2026-01-01')\n\ntx = df_transactions.copy()\n\n# Separar compras (monto positivo) de reembolsos (monto negativo)\ntx['is_refund'] = tx['amount_net'] < 0\n\nagg = tx.groupby('customer_id').agg(\n    num_transactions=('transaction_id', 'count'),\n    num_refunds=('is_refund', 'sum'),\n    total_spend=('amount_net', 'sum'),\n    avg_ticket=('amount_net', 'mean'),\n    max_ticket=('amount_net', 'max'),\n    last_tx_date=('transaction_date', 'max')\n).reset_index()\n\nagg['recency_days'] = (analysis_date - agg['last_tx_date']).dt.days\nagg['refund_rate'] = (agg['num_refunds'] / agg['num_transactions']).round(4)\n\n# Unir con atributos del cliente\ndf_customer_metrics = df_customers.merge(agg, on='customer_id', how='left')\n\n# Clientes sin transacciones: rellenamos con ceros y recency alta\ndf_customer_metrics['num_transactions'] = df_customer_metrics['num_transactions'].fillna(0).astype(int)\ndf_customer_metrics['num_refunds'] = df_customer_metrics['num_refunds'].fillna(0).astype(int)\ndf_customer_metrics['total_spend'] = df_customer_metrics['total_spend'].fillna(0.0)\ndf_customer_metrics['avg_ticket'] = df_customer_metrics['avg_ticket'].fillna(0.0)\ndf_customer_metrics['max_ticket'] = df_customer_metrics['max_ticket'].fillna(0.0)\ndf_customer_metrics['last_tx_date'] = df_customer_metrics['last_tx_date'].fillna(pd.NaT)\ndf_customer_metrics['recency_days'] = df_customer_metrics['recency_days'].fillna((analysis_date - df_customer_metrics['signup_date']).dt.days).astype(int)\ndf_customer_metrics['refund_rate'] = df_customer_metrics['refund_rate'].fillna(0.0)\n\ndf_customer_metrics.head()\n",
   "outputs": []
  },
  {
   "id": "fc0ac7ba",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 5) Exploración rápida del dataset\n# ============================================================\ndf_customer_metrics.info()\n\n",
   "outputs": []
  },
  {
   "id": "b50d13b6",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Estadísticas descriptivas de algunas variables numéricas clave\ndf_customer_metrics[['age', 'num_transactions', 'total_spend', 'avg_ticket', 'max_ticket', 'recency_days', 'refund_rate']].describe().T\n",
   "outputs": []
  },
  {
   "id": "ede26965",
   "cell_type": "markdown",
   "source": "### Preguntas guiadas para el Ejercicio 1\n\n1. ¿Qué columnas son **numéricas** y cuáles son **categóricas**?\n2. ¿Hay clientes con `num_transactions = 0`? ¿Qué significa en un caso real?\n3. Observa `total_spend`, `avg_ticket` y `max_ticket`. ¿Se intuye la presencia de valores extremos?\n4. ¿Qué variable te parece más útil para medir “actividad reciente” del cliente?\n\n> Guarda estas observaciones: te servirán para justificar decisiones en el Statistical Summary.\n",
   "metadata": {}
  },
  {
   "id": "18bdc3b9",
   "cell_type": "markdown",
   "source": "## 7.3 Análisis de valores atípicos y segmentación\n\n### 7.3.1 Identificando valores atípicos con reglas estadísticas (20 min)\n\nUn **valor atípico (outlier)** es una observación que se aleja significativamente del patrón general de los datos.\n\nEn analítica, los outliers suelen aparecer por:\n- **Errores de captura/ETL** (un cero de más, campos invertidos, tipos mal parseados).\n- **Eventos reales pero raros** (compras corporativas grandes, campañas, estacionalidad).\n- **Cambios de definición** (nuevas reglas de negocio, ajustes contables).\n\nDos reglas comunes para detectarlos:\n1. **IQR (Interquartile Range):** usa los percentiles 25% (Q1) y 75% (Q3).  \n   - Se define: `IQR = Q3 - Q1`  \n   - Outliers típicos: valores fuera de `[Q1 - 1.5*IQR, Q3 + 1.5*IQR]`\n2. **Z-score:** mide cuántas desviaciones estándar se aleja un punto de la media.  \n   - Se define: `z = (x - mean) / std`  \n   - Umbrales típicos: `|z| > 3` (depende del contexto y la distribución)\n\n**Nota práctica:** si la variable es muy asimétrica (por ejemplo, `total_spend`), IQR suele ser más robusto que Z-score.\n",
   "metadata": {}
  },
  {
   "id": "b48e0831",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.1 A) Detección de outliers con IQR en total_spend\n# ============================================================\nmetric = 'total_spend'\n\nq1 = df_customer_metrics[metric].quantile(0.25)\nq3 = df_customer_metrics[metric].quantile(0.75)\niqr = q3 - q1\n\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n\ndf_customer_metrics['outlier_iqr_total_spend'] = (\n    (df_customer_metrics[metric] < lower_bound) |\n    (df_customer_metrics[metric] > upper_bound)\n)\n\noutlier_count = df_customer_metrics['outlier_iqr_total_spend'].sum()\noutlier_pct = outlier_count / len(df_customer_metrics)\n\nprint(f\"IQR bounds para {metric}: [{lower_bound:,.2f}, {upper_bound:,.2f}]\")\nprint(f\"Outliers detectados (IQR): {outlier_count:,} ({outlier_pct:.2%})\")\n\ndf_customer_metrics.loc[df_customer_metrics['outlier_iqr_total_spend'], \n                        ['customer_id','plan','region','num_transactions','total_spend','max_ticket']].head(10)\n",
   "outputs": []
  },
  {
   "id": "8bbd0d58",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.1 B) Detección de outliers con Z-score en total_spend\n# ============================================================\n# Importante: Z-score asume una distribución relativamente \"normal\".\n# En variables con cola larga (como gasto), puede marcar demasiados outliers o no ser estable.\n\nmetric = 'total_spend'\nmean = df_customer_metrics[metric].mean()\nstd = df_customer_metrics[metric].std(ddof=0)\n\n# Para evitar división por cero\nif std == 0:\n    df_customer_metrics['z_total_spend'] = 0.0\nelse:\n    df_customer_metrics['z_total_spend'] = (df_customer_metrics[metric] - mean) / std\n\ndf_customer_metrics['outlier_z_total_spend'] = df_customer_metrics['z_total_spend'].abs() > 3\n\noutlier_count_z = df_customer_metrics['outlier_z_total_spend'].sum()\noutlier_pct_z = outlier_count_z / len(df_customer_metrics)\n\nprint(f\"Outliers detectados (Z-score |z|>3): {outlier_count_z:,} ({outlier_pct_z:.2%})\")\n\ndf_customer_metrics.loc[df_customer_metrics['outlier_z_total_spend'],\n                        ['customer_id','plan','num_transactions','total_spend','z_total_spend']].head(10)\n",
   "outputs": []
  },
  {
   "id": "8a941c7c",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.1 C) Visualización rápida (distribución + valores extremos)\n# ============================================================\nimport matplotlib.pyplot as plt\n\n# Histograma con límites razonables para ver la masa principal\nplt.figure(figsize=(10, 4))\nplt.hist(df_customer_metrics['total_spend'], bins=60)\nplt.title('Distribución de total_spend (incluye cola larga)')\nplt.xlabel('total_spend')\nplt.ylabel('frecuencia')\nplt.show()\n\n# Boxplot ayuda a ver \"cola\" y outliers (aunque comprime valores muy grandes)\nplt.figure(figsize=(10, 2.5))\nplt.boxplot(df_customer_metrics['total_spend'], vert=False)\nplt.title('Boxplot de total_spend')\nplt.xlabel('total_spend')\nplt.show()\n",
   "outputs": []
  },
  {
   "id": "26a152fc",
   "cell_type": "markdown",
   "source": "### Mini-ejercicio (5 min)\n\n1. Repite el análisis IQR para `max_ticket` y responde:\n   - ¿Cuántos outliers detectas?\n   - ¿Tiene sentido que existan tickets máximos muy altos?\n\n2. Repite el Z-score para `age` y revisa si detecta las edades extremas.\n\n> Tip: duplica el bloque de IQR y cambia `metric = 'max_ticket'`.\n",
   "metadata": {}
  },
  {
   "id": "6cddc51f",
   "cell_type": "markdown",
   "source": "### 7.3.2 Cómo abordar valores atípicos según el contexto (10 min)\n\nDetectar outliers es solo el primer paso. La decisión correcta depende del **contexto**:\n\n**Preguntas de negocio antes de actuar**\n- ¿El outlier es un **error** (captura/ETL) o un **evento real**?\n- ¿La métrica representa un **proceso diferente**? (ej.: reembolsos vs ventas)\n- ¿El outlier impacta el resultado del análisis? (medias, modelos, segmentación)\n\n**Estrategias comunes**\n1. **Validar y corregir** (si es error y hay fuente confiable).\n2. **Eliminar** (si es error sin corrección posible, y documentando impacto).\n3. **Capping / Winsorization**: recortar valores a percentiles (p. ej., 1% y 99%).\n4. **Transformación**: log, raíz, escalamiento robusto (útil para variables sesgadas).\n5. **Segmentar**: tratar los “casos especiales” como un grupo distinto (p. ej., cuentas corporativas).\n\nA continuación veremos ejemplos prácticos para `total_spend` y el caso especial de reembolsos.\n",
   "metadata": {}
  },
  {
   "id": "bf60cd80",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.2 A) Separar reembolsos del gasto total (contexto)\n# ============================================================\n# Nota: total_spend ya incluye negativos porque sumamos amount_net.\n# Si queremos \"gasto bruto\" sin reembolsos, podemos calcularlo aparte.\n\ntx_pos = df_transactions[df_transactions['amount_net'] > 0].copy()\ntx_neg = df_transactions[df_transactions['amount_net'] < 0].copy()\n\nspend_pos = tx_pos.groupby('customer_id')['amount_net'].sum().rename('spend_positive')\nspend_neg = tx_neg.groupby('customer_id')['amount_net'].sum().rename('refund_amount')  # negativo\n\ndf_customer_metrics = df_customer_metrics.merge(spend_pos, on='customer_id', how='left')\ndf_customer_metrics = df_customer_metrics.merge(spend_neg, on='customer_id', how='left')\n\ndf_customer_metrics['spend_positive'] = df_customer_metrics['spend_positive'].fillna(0.0)\ndf_customer_metrics['refund_amount'] = df_customer_metrics['refund_amount'].fillna(0.0)\n\n# Métrica alternativa: net_spend = spend_positive + refund_amount (refund_amount es negativo)\ndf_customer_metrics['net_spend'] = df_customer_metrics['spend_positive'] + df_customer_metrics['refund_amount']\n\ndf_customer_metrics[['customer_id','spend_positive','refund_amount','net_spend','refund_rate']].head()\n",
   "outputs": []
  },
  {
   "id": "7843b652",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.2 B) Capping (recorte) usando percentil 99 para net_spend\n# ============================================================\nmetric = 'net_spend'\np99 = df_customer_metrics[metric].quantile(0.99)\n\ndf_customer_metrics['net_spend_capped_p99'] = df_customer_metrics[metric].clip(upper=p99)\n\nprint(f\"Percentil 99 de {metric}: {p99:,.2f}\")\ndf_customer_metrics[[metric, 'net_spend_capped_p99']].describe().T\n",
   "outputs": []
  },
  {
   "id": "fcce2b2b",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.2 C) Transformación logarítmica (para cola larga)\n# ============================================================\n# log1p(x) = log(1+x) evita problemas con x=0.\n# Nota: si hay valores negativos, primero definimos una métrica no-negativa.\n# Aquí usamos spend_positive (solo compras).\n\ndf_customer_metrics['log_spend_positive'] = np.log1p(df_customer_metrics['spend_positive'])\n\ndf_customer_metrics[['spend_positive', 'log_spend_positive']].describe().T\n",
   "outputs": []
  },
  {
   "id": "a7b18e68",
   "cell_type": "markdown",
   "source": "### Pregunta clave\n\nSi estás construyendo un **segmento “VIP”** basado en gasto, ¿es mejor usar:\n- `total_spend` (incluye reembolsos),\n- `spend_positive` (solo compras),\n- `net_spend` (compras + reembolsos),\n- o `net_spend_capped_p99` (recortado)?\n\nNo hay una única respuesta. Debes justificarla con el objetivo del análisis.\n",
   "metadata": {}
  },
  {
   "id": "08966e9b",
   "cell_type": "markdown",
   "source": "### 7.3.3 Segmentación de clientes con sentencias if (15 min)\n\nLa **segmentación** consiste en agrupar clientes con características similares para:\n- Analizar comportamiento (retención, churn, monetización).\n- Definir estrategias (promociones, atención, pricing).\n- Comparar desempeño por grupo.\n\nEn Python, una forma didáctica de segmentar es con **sentencias `if/elif/else`**.\n\nEn este ejemplo crearemos un segmento simple tipo **RFM-lite** (sin puntajes):\n- **Recency (R):** días desde la última compra (`recency_days`)\n- **Monetary (M):** gasto neto (`net_spend`)\n\nReglas (ejemplo):\n- `VIP`: gasto alto y compra reciente\n- `Leal`: compra reciente con gasto medio\n- `En riesgo`: hace mucho que no compra, pero antes gastaba\n- `Nuevo / Inactivo`: poco gasto y poca actividad\n",
   "metadata": {}
  },
  {
   "id": "e90a3d1a",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.3 A) Función con if/elif/else para segmentación\n# ============================================================\ndef segment_customer(recency_days: int, net_spend: float) -> str:\n    \"\"\"Asigna un segmento basado en recencia y gasto.\n\n    Parámetros\n    ----------\n    recency_days : int\n        Días desde la última transacción (menor = más reciente).\n    net_spend : float\n        Gasto neto total (compras + reembolsos).\n\n    Retorna\n    -------\n    str\n        Nombre del segmento.\n    \"\"\"\n    if (net_spend >= 2000) and (recency_days <= 30):\n        return 'VIP'\n    elif (net_spend >= 800) and (recency_days <= 60):\n        return 'Leal'\n    elif (net_spend >= 800) and (recency_days > 60):\n        return 'En riesgo'\n    else:\n        return 'Nuevo / Inactivo'\n\n# Aplicar la función a dos columnas (vectorizando con apply sobre filas es simple de entender,\n# aunque para grandes volúmenes puede ser más lento que alternativas vectorizadas).\ndf_customer_metrics['segment_if'] = df_customer_metrics.apply(\n    lambda row: segment_customer(row['recency_days'], row['net_spend']),\n    axis=1\n)\n\ndf_customer_metrics['segment_if'].value_counts(dropna=False)\n",
   "outputs": []
  },
  {
   "id": "633952ca",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Ver algunos ejemplos por segmento\n(df_customer_metrics[['customer_id','plan','recency_days','net_spend','segment_if']]\n .sort_values(['segment_if','net_spend'], ascending=[True, False])\n .head(15))\n",
   "outputs": []
  },
  {
   "id": "fdad924e",
   "cell_type": "markdown",
   "source": "### Mini-ejercicio (5 min)\n\nAjusta los umbrales (por ejemplo, el gasto de VIP o la ventana de recencia) y observa:\n- Cómo cambia el tamaño de cada segmento.\n- Si el segmento VIP queda “demasiado grande” o “demasiado pequeño”.\n\n**Regla práctica:** los umbrales deberían tener sentido para tu caso de negocio y ser estables en el tiempo.\n",
   "metadata": {}
  },
  {
   "id": "b33f4699",
   "cell_type": "markdown",
   "source": "### 7.3.4 Segmentación usando IF y `apply()` con funciones que crean nuevas columnas (10 min)\n\nA veces una segmentación requiere múltiples salidas:\n- `segment` (etiqueta)\n- `risk_flag` (bandera de riesgo)\n- `recommended_action` (acción sugerida)\n\nPodemos encapsular esa lógica en una función y devolver un `pd.Series` para crear **varias columnas** con `apply()`.\n",
   "metadata": {}
  },
  {
   "id": "61e3f1d0",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.4 A) Función que retorna múltiples columnas\n# ============================================================\ndef segment_and_action(recency_days: int, net_spend: float, refund_rate: float) -> pd.Series:\n    \"\"\"Devuelve segmento, bandera de riesgo y acción sugerida.\n\n    La idea no es que estas reglas sean 'perfectas', sino mostrar cómo:\n    - integrar IFs,\n    - manejar casos especiales,\n    - crear múltiples columnas de salida.\n    \"\"\"\n    # 1) Caso especial: alta tasa de reembolsos\n    if refund_rate >= 0.20 and net_spend > 0:\n        return pd.Series({\n            'segment_v2': 'Reembolsos altos',\n            'risk_flag': 'ALTO',\n            'recommended_action': 'Revisar políticas / fraude / experiencia'\n        })\n\n    # 2) Segmentación principal por recencia + gasto\n    if (net_spend >= 2000) and (recency_days <= 30):\n        return pd.Series({'segment_v2': 'VIP', 'risk_flag': 'BAJO', 'recommended_action': 'Upsell + atención prioritaria'})\n    elif (net_spend >= 800) and (recency_days <= 60):\n        return pd.Series({'segment_v2': 'Leal', 'risk_flag': 'BAJO', 'recommended_action': 'Cross-sell + fidelización'})\n    elif (net_spend >= 800) and (recency_days > 60):\n        return pd.Series({'segment_v2': 'En riesgo', 'risk_flag': 'MEDIO', 'recommended_action': 'Campaña de reactivación'})\n    else:\n        # Nota: net_spend puede ser 0 si nunca compró\n        if recency_days <= 30:\n            return pd.Series({'segment_v2': 'Nuevo', 'risk_flag': 'MEDIO', 'recommended_action': 'Onboarding / activación'})\n        return pd.Series({'segment_v2': 'Inactivo', 'risk_flag': 'ALTO', 'recommended_action': 'Winback o limpieza de CRM'})\n\n# Aplicación: axis=1 para leer cada fila (didáctico).\nnew_cols = df_customer_metrics.apply(\n    lambda row: segment_and_action(row['recency_days'], row['net_spend'], row['refund_rate']),\n    axis=1\n)\n\ndf_customer_metrics = pd.concat([df_customer_metrics, new_cols], axis=1)\n\ndf_customer_metrics[['segment_v2','risk_flag','recommended_action']].value_counts().head(10)\n",
   "outputs": []
  },
  {
   "id": "6a5c543b",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# Distribución por segmento_v2 (tabla de conteos + porcentaje)\nseg_dist = (df_customer_metrics['segment_v2']\n            .value_counts()\n            .rename_axis('segment_v2')\n            .reset_index(name='count'))\nseg_dist['pct'] = seg_dist['count'] / seg_dist['count'].sum()\nseg_dist\n",
   "outputs": []
  },
  {
   "id": "d5690511",
   "cell_type": "markdown",
   "source": "### Nota técnica (para cuando avances)\n\n`apply(axis=1)` es muy claro para aprender, pero puede ser más lento en datasets grandes.  \nAlternativas comunes para producción:\n- `np.select()` (vectorizado)\n- `pd.cut()` (bins)\n- reglas SQL en el DW/BI\n- modelos (clustering, scoring, etc.)\n\nHoy priorizamos claridad conceptual y buenas prácticas de lectura.\n",
   "metadata": {}
  },
  {
   "id": "8d49329a",
   "cell_type": "markdown",
   "source": "### 7.3.5 Redacción de un Statistical Summary (8 min)\n\nUn **Statistical Summary** es un texto corto (1–2 páginas, a veces menos) que resume:\n\n1. **Objetivo del análisis** (pregunta de negocio).\n2. **Datos usados** (fuente, periodo, tamaño, variables relevantes).\n3. **Métodos** (reglas de outliers, segmentación, métricas).\n4. **Hallazgos clave** (números concretos, comparaciones, insights).\n5. **Limitaciones** (supuestos, sesgos, calidad de datos).\n6. **Recomendaciones / próximos pasos**.\n\nEl propósito es que una persona no técnica pueda entender:\n- qué hiciste,\n- qué encontraste,\n- y qué debería hacerse después.\n\nA continuación generamos algunos números que suelen alimentar ese resumen.\n",
   "metadata": {}
  },
  {
   "id": "83e608c7",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# 7.3.5 A) KPIs de contexto para el summary\n# ============================================================\nfrom IPython.display import display\nn = len(df_customer_metrics)\n\n# Outliers (ejemplo): según IQR en total_spend\nout_iqr = df_customer_metrics['outlier_iqr_total_spend'].sum()\nout_iqr_pct = out_iqr / n\n\n# Segmentos\nseg_counts = df_customer_metrics['segment_v2'].value_counts()\nvip_count = seg_counts.get('VIP', 0)\nrisk_high = (df_customer_metrics['risk_flag'] == 'ALTO').sum()\n\n# Métricas descriptivas (usando spend_positive para evitar negativos)\nspend_desc = df_customer_metrics['spend_positive'].describe()\n\nprint(f\"Clientes: {n:,}\")\nprint(f\"Outliers IQR (total_spend): {out_iqr:,} ({out_iqr_pct:.2%})\")\nprint(f\"VIP (segment_v2): {vip_count:,} ({vip_count/n:.2%})\")\nprint(f\"Riesgo ALTO: {risk_high:,} ({risk_high/n:.2%})\")\nprint('\\nDescriptivos spend_positive:')\ndisplay(spend_desc)\n",
   "outputs": []
  },
  {
   "id": "3972049c",
   "cell_type": "markdown",
   "source": "#### Ejemplo de Statistical Summary (plantilla)\n\nCompleta los campos con tus números (puedes copiar/pegar y editar):\n\n**Objetivo:**  \nAnalizar patrones de gasto y actividad de clientes, identificar valores atípicos y proponer segmentos accionables para estrategias de retención y monetización.\n\n**Datos:**  \n- Base sintética de clientes: `n = {n:,}`  \n- Periodo de transacciones: 2024-01-01 a 2025-12-31  \n- Variables clave: `net_spend`, `spend_positive`, `recency_days`, `refund_rate`, `plan`, `acquisition_channel`, `region`.\n\n**Método:**  \n- Outliers detectados con IQR sobre `total_spend`.  \n- Tratamiento: separación de reembolsos + capping p99 para robustez en análisis agregados.  \n- Segmentación por reglas (recencia + gasto) con casos especiales de reembolsos altos.\n\n**Hallazgos clave (ejemplo):**\n- Se detectaron **{out_iqr:,} outliers** en `total_spend` (**{out_iqr_pct:.2%}**).  \n- El segmento **VIP** representa **{vip_count:,} clientes** (**{vip_count/n:.2%}**).  \n- Clientes con **riesgo ALTO**: **{risk_high:,}** (**{risk_high/n:.2%}**).  \n- Recomendación: priorizar campañas de reactivación para “En riesgo” y revisar causas para “Reembolsos altos”.\n\n**Limitaciones:**  \n- Dataset sintético; en producción validar con fuentes reales y reglas contables.  \n- Los umbrales de segmentación deben calibrarse con criterios de negocio y estacionalidad.\n\n**Próximos pasos:**  \n- Validar outliers con equipo de negocio (operaciones/finanzas).  \n- Ajustar umbrales por plan/región.  \n- Construir dashboard con distribución de segmentos y evolución mensual.\n",
   "metadata": {}
  },
  {
   "id": "c0c83809",
   "cell_type": "markdown",
   "source": "## 7.4 Almacenando y compartiendo análisis (12 min)\n\nEn analítica profesional, no basta con “tener un notebook que funciona”:\n- necesitas **reproducibilidad**, **colaboración** y **trazabilidad**.\n\nGitHub (Git) es el estándar para lograrlo.\n\n### 7.4.1 GitHub para analistas: conceptos e importancia\n\n**Conceptos clave**\n- **Repositorio (repo):** carpeta versionada con historial.\n- **Commit:** “foto” del estado del proyecto con mensaje.\n- **Branch:** línea de trabajo paralela (p. ej., `main`, `feature/outliers`).\n- **Pull Request (PR):** revisión e integración de cambios.\n- **Issues:** tareas y seguimiento.\n\n**Valor para analistas**\n- Historial de cambios y decisiones (auditable).\n- Colaboración con revisiones (PR).\n- Estandariza estructura y documentación (README).\n- Facilita despliegues y automatización (CI/CD).\n",
   "metadata": {}
  },
  {
   "id": "e12c9cae",
   "cell_type": "markdown",
   "source": "### 7.4.2 Repos & estructura de proyectos (configuración inicial)\n\nUna estructura simple y útil para análisis:\n\n```\nmi-proyecto-analitica/\n├─ data/                # datos (ideal: no subir datos sensibles)\n│  ├─ raw/              # datos crudos (solo lectura)\n│  └─ processed/        # datos listos para análisis\n├─ notebooks/           # notebooks exploratorios\n├─ src/                 # funciones reutilizables (python)\n├─ reports/             # resultados: tablas, figuras, pdf\n├─ README.md            # qué es, cómo correrlo\n├─ requirements.txt     # dependencias\n└─ .gitignore           # excluir archivos (data pesada, credenciales)\n```\n\n**Buenas prácticas mínimas**\n- Los notebooks van a `notebooks/`.\n- Lo reusable va a `src/` (funciones para outliers, segmentación).\n- Documenta en `README.md` cómo reproducir.\n- Usa `.gitignore` para excluir datos sensibles, caches, credenciales.\n",
   "metadata": {}
  },
  {
   "id": "1a6fcae2",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": "# ============================================================\n# (Demo opcional) Crear una estructura de proyecto local\n# ============================================================\n# En Colab o en tu máquina puedes crear la estructura base.\n# Este bloque NO sube nada a GitHub; solo crea carpetas.\nimport os\n\nproject_root = 'mi-proyecto-analitica'\nfolders = [\n    f'{project_root}/data/raw',\n    f'{project_root}/data/processed',\n    f'{project_root}/notebooks',\n    f'{project_root}/src',\n    f'{project_root}/reports'\n]\n\nfor folder in folders:\n    os.makedirs(folder, exist_ok=True)\n\n# Crear archivos básicos\nreadme_path = f'{project_root}/README.md'\ngitignore_path = f'{project_root}/.gitignore'\nrequirements_path = f'{project_root}/requirements.txt'\n\nif not os.path.exists(readme_path):\n    with open(readme_path, 'w', encoding='utf-8') as f:\n        f.write('# Mi proyecto de analítica\\n\\nDescripción corta del objetivo del análisis.\\n')\n\nif not os.path.exists(gitignore_path):\n    with open(gitignore_path, 'w', encoding='utf-8') as f:\n        f.write('data/raw/\\ndata/processed/\\n__pycache__/\\n.ipynb_checkpoints/\\n.env\\n')\n\nif not os.path.exists(requirements_path):\n    with open(requirements_path, 'w', encoding='utf-8') as f:\n        f.write('pandas\\nnumpy\\nmatplotlib\\n')\n\nprint('Estructura creada en:', project_root)\n",
   "outputs": []
  },
  {
   "id": "302682a6",
   "cell_type": "markdown",
   "source": "### 7.4.3 Aplicando GitHub Workflow con Google Colab\n\n**Objetivo:** editar un notebook en Colab y versionarlo en GitHub con un workflow básico.\n\n**Pasos típicos (resumen):**\n1. Crear repo en GitHub: `mi-proyecto-analitica`.\n2. Abrir Google Colab → montar Drive (opcional).\n3. Clonar el repo en Colab:\n   - `!git clone <URL_DEL_REPO>`\n4. Crear una rama de trabajo:\n   - `!git checkout -b feature/segmentacion`\n5. Realizar cambios (notebook, README, scripts).\n6. Guardar, agregar y hacer commit:\n   - `!git status`\n   - `!git add .`\n   - `!git commit -m \"Agregar segmentación v2 y resumen estadístico\"`\n7. Subir la rama a GitHub:\n   - `!git push origin feature/segmentacion`\n8. Abrir Pull Request en GitHub y solicitar revisión.\n\n**Consejo:** en equipos, evita hacer cambios directos en `main`. Trabaja por ramas y PRs.\n",
   "metadata": {}
  },
  {
   "id": "eb3ea272",
   "cell_type": "markdown",
   "source": "## 6. Take aways de la sesión teórica\n\nAl terminar esta sesión, deberías llevarte estas ideas clave:\n\n- Un outlier es un **síntoma**: puede ser error, evento raro o señal de negocio.\n- IQR y Z-score son reglas útiles, pero **no sustituyen** el criterio y el contexto.\n- Tratar outliers implica decisiones: validar, eliminar, recortar, transformar o segmentar.\n- Segmentación con reglas (IF, apply) es una base práctica para análisis accionables.\n- Un Statistical Summary transforma código en **comunicación de negocio**.\n- GitHub permite reproducibilidad, colaboración y trazabilidad: “sin control de versiones, el análisis no es profesional”.\n",
   "metadata": {}
  },
  {
   "id": "1effe8d3",
   "cell_type": "markdown",
   "source": "## 7. Cierre y próximos pasos\n\nPara seguir profundizando:\n\n1. Implementa la versión vectorizada de segmentación con `np.select()` y compárala con `apply()`.\n2. Crea un pequeño dashboard (matplotlib) con:\n   - distribución de segmentos,\n   - gasto promedio por segmento,\n   - recencia promedio por segmento.\n3. Monta un repo en GitHub con la estructura propuesta y sube:\n   - este notebook,\n   - un `README.md`,\n   - un `.gitignore`.\n",
   "metadata": {}
  },
  {
   "id": "e004b400",
   "cell_type": "markdown",
   "source": "## 8. Información complementaria y recursos\n\n- Documentación de pandas (apply, groupby, describe):  \n  <https://pandas.pydata.org/docs/>\n- Outliers y estadística robusta (conceptos):  \n  - IQR (Tukey’s fences)  \n  - Z-score (normalización)\n- Git y GitHub:\n  - Git Book (documentación oficial): <https://git-scm.com/book/en/v2>\n  - GitHub Docs: <https://docs.github.com/>\n- Google Colab + Git:\n  - Guías de “clone / commit / push” en Colab (varían por credenciales/entorno)\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cierre\n",
    "**Kahoot de repaso (5 min)**\n",
    "- Profundizamos en la detección de anomalías y segmentación.\n",
    "- Vimos cómo usar reglas estadísticas para flaggear transacciones sospechosas.\n",
    "\n",
    "**Reflexión:**\n",
    "- ¿Es lo mismo un outlier que un error de datos? ¿Por qué?\n",
    "- ¿Cómo aporta valor al negocio segmentar a los clientes?\n",
    "\n",
    "**Q&A y próximos pasos.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siguientes Pasos\n",
    "- **Próxima sesión:** Sprint 7 - Proyecto final del sprint: Clínica Agendada.\n",
    "- **Participación:** Revisa los conceptos de media, mediana y desviación estándar.\n",
    "- **Recordatorios:** Prepara tu entorno para el proyecto integrado.\n"
   ]
  }
 ]
}