{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 7 · Webinar 22 · Data Analytics práctico (Proyecto: outliers, segmentación y GitHub)\n",
    "\n",
    "**Duración:** 100 minutos  \n",
    "**Modalidad:** Práctica guiada (proyecto paso a paso)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fecha\n",
    "\n",
    "Completa la información de la sesión:\n",
    "\n",
    "- **Fecha:**  \n",
    "- **Instructor/a:**  \n",
    "- **Duración:** 100 minutos  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos de la sesión práctica\n",
    "\n",
    "Al finalizar esta sesión, la persona estudiante será capaz de:\n",
    "\n",
    "1. **Generar y documentar** un dataset sintético realista (CSV) para un proyecto práctico.\n",
    "2. Realizar **carga, limpieza y exploración** de datos (tipos, nulos, duplicados, calidad).\n",
    "3. Construir **métricas por cliente** (agregaciones tipo RFM y KPIs operativos).\n",
    "4. **Detectar y tratar valores atípicos** usando reglas estadísticas (IQR/Z-score) y criterio de negocio.\n",
    "5. Crear **segmentos de clientes** con `if/elif/else` y con `apply()` usando funciones personalizadas.\n",
    "6. Redactar un **Statistical Summary** (hallazgos clave + métricas + decisiones tomadas).\n",
    "7. Empaquetar, versionar y **publicar el proyecto en GitHub** (estructura de repo + workflow).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa87d0c",
   "metadata": {},
   "source": [
    "## Metodología de la sesión\n",
    "\n",
    "**Vamos a realizar nuestro primer proyecto para nuestro portafolio!**\n",
    "\n",
    "Comparte con los estudoantes el dataset que vamos a utilizar. Más adelante encontrarás detalles sobre el dataset (Lo podés encontrar sobre la carpeta `datasets`).\n",
    "\n",
    "- Cada estudiante replica el notebook en su propio espacio de Google Colab.\n",
    "- La practica de Git incluirá crear un repositorio en GitHub y subir el notebook.\n",
    "- Estudiar los comandos básicos de Git editando el archivo README.md.\n",
    "- Estudiar los comandos básicos de Git subiendo el .csv del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda sugerida (100 minutos)\n",
    "\n",
    "| Tiempo | Bloque | Contenido | Modalidad |\n",
    "|---:|---|---|---|\n",
    "| 10 min | Contexto del proyecto | Caso de uso, entregables y dataset | Guía |\n",
    "| 15 min | Dataset (CSV) + carga | Generación, diccionario de datos, lectura | Live coding |\n",
    "| 20 min | Calidad + EDA | Tipos, nulos, duplicados, distribuciones | Ejercicio guiado |\n",
    "| 20 min | Métricas por cliente | Agregaciones y KPIs (RFM básico) | Ejercicio guiado |\n",
    "| 20 min | Outliers | Detección (IQR/Z) + tratamiento por contexto | Ejercicio guiado |\n",
    "| 10 min | Segmentación | `if` + `apply()` con función | Ejercicio guiado |\n",
    "| 5 min | Statistical Summary | Plantilla + texto basado en KPIs | Guía |\n",
    "| 10 min | Publicación en GitHub | Estructura, commits, push, Colab workflow | Guía práctica |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 0 · Kickoff del proyecto (5 min)\n",
    "\n",
    "En parejas (o individual), responde:\n",
    "\n",
    "1. ¿Qué decisiones de negocio podríamos tomar con estos datos?\n",
    "2. ¿Qué variables crees que tendrán outliers y por qué?\n",
    "3. ¿Qué significa “segmento” para ti en este contexto (retención, VIP, riesgo)?\n",
    "\n",
    "**Salida esperada:** 3–5 bullets con hipótesis iniciales.  \n",
    "Luego validaremos (o corregiremos) esas hipótesis con datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto práctico: “Clínica Agendada” (Customer Analytics)\n",
    "\n",
    "Vas a trabajar como analista en una empresa que ofrece servicios de salud bajo agenda. El negocio quiere responder:\n",
    "\n",
    "- ¿Cómo se comportan los clientes por plan, canal y ciudad?\n",
    "- ¿Qué tan frecuentes son los **reembolsos** y cómo afectan los ingresos?\n",
    "- ¿Existen **valores atípicos** (montos, tiempos de espera, edades) que distorsionen el análisis?\n",
    "- ¿Podemos **segmentar** clientes para acciones (retención, cross-sell, incentivos)?\n",
    "\n",
    "### Entregables del proyecto (lo que publicaremos en GitHub)\n",
    "1. Un dataset **en CSV** (generado en el notebook).\n",
    "2. Un notebook reproducible con:\n",
    "   - Limpieza + EDA\n",
    "   - Detección y tratamiento de outliers\n",
    "   - Segmentación (if + apply)\n",
    "   - Statistical Summary\n",
    "3. Artefactos en el repo:\n",
    "   - `README.md`\n",
    "   - `data/clinic_transactions.csv`\n",
    "   - `outputs/customer_metrics.csv`\n",
    "   - `outputs/statistical_summary.md`\n",
    "   - `figures/` (opcional: gráficos exportados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diccionario de datos (CSV)\n",
    "\n",
    "El archivo contiene **transacciones / citas** (1 fila = 1 cita facturada o reembolsada) con atributos del cliente.\n",
    "\n",
    "| Columna | Tipo | Descripción |\n",
    "|---|---|---|\n",
    "| `transaction_id` | str | ID único de la transacción |\n",
    "| `customer_id` | str | ID del cliente |\n",
    "| `appointment_date` | datetime | Fecha de la cita/transacción |\n",
    "| `service_type` | category | Tipo de servicio (consulta, laboratorio, etc.) |\n",
    "| `appointment_channel` | category | Canal de agenda (Web/App/Call Center/Presencial) |\n",
    "| `payment_method` | category | Método de pago |\n",
    "| `amount_gross` | float | Valor bruto antes de descuentos |\n",
    "| `discount_pct` | int | % de descuento aplicado |\n",
    "| `amount_net` | float | Valor neto (negativo si es reembolso) |\n",
    "| `is_refund` | int | 1 si es reembolso, 0 si no |\n",
    "| `refund_reason` | str | Motivo de reembolso (si aplica) |\n",
    "| `wait_time_min` | float | Tiempo de espera (minutos) |\n",
    "| `service_duration_min` | float | Duración del servicio (minutos) |\n",
    "| `satisfaction_score` | float | Satisfacción (esperado 1–10; contiene nulos/outliers) |\n",
    "| `signup_date` | datetime | Fecha de registro del cliente |\n",
    "| `age` | int | Edad (contiene valores sucios/outliers) |\n",
    "| `gender` | category | Género (F/M/X) |\n",
    "| `city` | category | Ciudad |\n",
    "| `acquisition_channel` | category | Canal de adquisición |\n",
    "| `plan` | category | Plan (Básico/Plus/Premium) |\n",
    "| `has_insurance` | int | 1 si tiene seguro, 0 si no |\n",
    "| `is_revenue` | int | 1 si `amount_net` > 0 (ingreso), 0 si no |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0) Setup del proyecto\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (Opcional) Para ver más columnas en pantalla\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# (Opcional) Semilla para reproducibilidad\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "print(\"Entorno listo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 · Generar el dataset sintético (CSV)\n",
    "\n",
    "En proyectos reales, a veces necesitas **simular datos** para probar análisis, dashboards o pipelines.\n",
    "\n",
    "En este ejercicio:\n",
    "- Generaremos un dataset realista de transacciones (citas) y lo guardaremos como CSV.\n",
    "- Luego trabajaremos **solo** a partir del CSV (como en un proyecto real).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Puedes encontrar el dataset en el archivo \"datasets/sprint7_webinar22_clinic_transactions.csv\"\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# df_preview = pd.read_csv(csv_file)\n",
    "# df_preview.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 · Cargar el CSV y revisar calidad de datos (EDA rápido)\n",
    "\n",
    "En un proyecto real, lo primero es responder:\n",
    "\n",
    "- ¿Cuántas filas/columnas tenemos?\n",
    "- ¿Hay valores nulos? ¿En qué columnas?\n",
    "- ¿Hay duplicados?\n",
    "- ¿Los tipos de datos (fechas/números) son correctos?\n",
    "\n",
    "**Meta:** terminar con un dataframe listo para análisis (con tipos correctos y flags útiles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) Cargar CSV y EDA rápido\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# Tipos de datos actuales\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisión de nulos y duplicados\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "display(missing.head(10))\n",
    "\n",
    "print(\"Duplicados (filas completas):\", df.duplicated().sum())\n",
    "print(\"Duplicados por transaction_id:\", df[\"transaction_id\"].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a datetime columnas de fecha\n",
    "df[\"appointment_date\"] = pd.to_datetime(df[\"appointment_date\"], errors=\"coerce\")\n",
    "df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], errors=\"coerce\")\n",
    "\n",
    "# Validar conversiones\n",
    "print(\"Fechas inválidas (appointment_date):\", df[\"appointment_date\"].isna().sum())\n",
    "print(\"Fechas inválidas (signup_date):\", df[\"signup_date\"].isna().sum())\n",
    "\n",
    "df[[\"appointment_date\",\"signup_date\"]].describe(datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 · Construir métricas por cliente (base para análisis y segmentación)\n",
    "\n",
    "En la práctica, la segmentación suele hacerse con variables agregadas.  \n",
    "Vamos a construir un dataframe de métricas por cliente, por ejemplo:\n",
    "\n",
    "- `num_visits`: número de citas\n",
    "- `total_spend`: gasto total (solo ingresos, excluyendo reembolsos)\n",
    "- `refund_count` y `refund_rate`\n",
    "- `avg_ticket` y `max_ticket`\n",
    "- `last_visit_date` y `recency_days` (días desde la última cita)\n",
    "- KPIs operativos: `avg_wait_time`, `avg_duration`, `avg_satisfaction`\n",
    "\n",
    "**Nota:** aquí aplicamos `groupby` + `agg`, que es una habilidad esencial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Métricas por cliente (agregación)\n",
    "# ============================================================\n",
    "\n",
    "# Separar ingresos vs reembolsos\n",
    "df[\"is_refund\"] = df[\"is_refund\"].astype(int)\n",
    "\n",
    "df_revenue = df[df[\"amount_net\"] > 0].copy()\n",
    "df_refunds = df[df[\"amount_net\"] < 0].copy()\n",
    "\n",
    "print(\"Ingresos:\", len(df_revenue), \"| Reembolsos:\", len(df_refunds))\n",
    "\n",
    "# Fecha de corte del análisis (simula “hoy” en un proyecto)\n",
    "as_of_date = df[\"appointment_date\"].max()\n",
    "as_of_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregación por cliente\n",
    "customer_metrics = (\n",
    "    df.groupby(\"customer_id\")\n",
    "      .agg(\n",
    "          num_visits=(\"transaction_id\",\"nunique\"),\n",
    "          total_spend=(\"amount_net\", lambda s: s[s>0].sum()),      # solo ingresos\n",
    "          refund_count=(\"is_refund\",\"sum\"),\n",
    "          avg_ticket=(\"amount_net\", lambda s: s[s>0].mean()),\n",
    "          max_ticket=(\"amount_net\", lambda s: s[s>0].max()),\n",
    "          last_visit_date=(\"appointment_date\",\"max\"),\n",
    "          avg_wait_time=(\"wait_time_min\",\"mean\"),\n",
    "          avg_duration=(\"service_duration_min\",\"mean\"),\n",
    "          avg_satisfaction=(\"satisfaction_score\",\"mean\"),\n",
    "          city=(\"city\",\"first\"),\n",
    "          plan=(\"plan\",\"first\"),\n",
    "          acquisition_channel=(\"acquisition_channel\",\"first\"),\n",
    "          age=(\"age\",\"first\"),\n",
    "          has_insurance=(\"has_insurance\",\"first\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Recency en días\n",
    "customer_metrics[\"recency_days\"] = (as_of_date - customer_metrics[\"last_visit_date\"]).dt.days\n",
    "\n",
    "# Refund rate (por visitas)\n",
    "customer_metrics[\"refund_rate\"] = customer_metrics[\"refund_count\"] / customer_metrics[\"num_visits\"]\n",
    "\n",
    "display(customer_metrics.head())\n",
    "customer_metrics.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-ejercicio (5 min)\n",
    "\n",
    "1. Calcula el **percentil 90** de `total_spend` y úsalo para identificar los clientes “Top 10%”.\n",
    "2. Crea una columna `is_top_spender` (1 si está en el Top 10%, 0 si no).\n",
    "\n",
    "Pista: `customer_metrics[\"total_spend\"].quantile(0.90)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución (Mini-ejercicio)\n",
    "p90 = customer_metrics[\"total_spend\"].quantile(0.90)\n",
    "customer_metrics[\"is_top_spender\"] = (customer_metrics[\"total_spend\"] >= p90).astype(int)\n",
    "\n",
    "p90, customer_metrics[\"is_top_spender\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.1 · Identificando valores atípicos con reglas estadísticas (aplicación práctica)\n",
    "\n",
    "En el webinar teórico vimos dos reglas comunes:\n",
    "\n",
    "- **IQR (Interquartile Range):** robusto para distribuciones sesgadas (típico en montos).\n",
    "- **Z-score:** útil si la variable es aproximadamente normal (o tras transformar).\n",
    "\n",
    "En un proyecto real, esto se traduce en:\n",
    "1. Medir cuántos outliers hay.\n",
    "2. Inspeccionar ejemplos (¿errores? ¿casos reales extremos?).\n",
    "3. Decidir tratamiento (no siempre se eliminan).\n",
    "\n",
    "En este ejercicio analizaremos outliers en:\n",
    "- `amount_net` (en ingresos)\n",
    "- `wait_time_min`\n",
    "- `age` (calidad de datos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.1 A) Detección de outliers con IQR (ejemplo: total_spend)\n",
    "# ============================================================\n",
    "\n",
    "metric = \"total_spend\"\n",
    "\n",
    "q1 = customer_metrics[metric].quantile(0.25)\n",
    "q3 = customer_metrics[metric].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "customer_metrics[\"outlier_iqr_total_spend\"] = ((customer_metrics[metric] < lower) | (customer_metrics[metric] > upper)).astype(int)\n",
    "\n",
    "print(\"IQR bounds:\", lower, upper)\n",
    "customer_metrics[\"outlier_iqr_total_spend\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver ejemplos de outliers (top 10 por total_spend)\n",
    "outliers_spend = customer_metrics[customer_metrics[\"outlier_iqr_total_spend\"] == 1].sort_values(\"total_spend\", ascending=False)\n",
    "display(outliers_spend.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.1 B) Detección de outliers con Z-score (ejemplo: wait_time_min)\n",
    "# ============================================================\n",
    "\n",
    "# Para Z-score es mejor usar una variable por transacción (aquí: wait_time_min)\n",
    "wait = df[\"wait_time_min\"].dropna()\n",
    "\n",
    "mean_w = wait.mean()\n",
    "std_w = wait.std(ddof=0)\n",
    "\n",
    "z = (df[\"wait_time_min\"] - mean_w) / std_w\n",
    "df[\"outlier_z_wait_time\"] = (z.abs() > 3).astype(int)\n",
    "\n",
    "df[\"outlier_z_wait_time\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización rápida (histograma) para entender sesgo y outliers\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df_revenue[\"amount_net\"], bins=50)\n",
    "plt.title(\"Distribución de amount_net (solo ingresos)\")\n",
    "plt.xlabel(\"amount_net\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df[\"wait_time_min\"], bins=50)\n",
    "plt.title(\"Distribución de wait_time_min\")\n",
    "plt.xlabel(\"wait_time_min\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.2 · Cómo abordar valores atípicos según el contexto (aplicación práctica)\n",
    "\n",
    "Regla de oro: **outlier ≠ error**.  \n",
    "Un outlier puede ser:\n",
    "\n",
    "- Un **error de captura** (edad = 999, satisfacción = 12)\n",
    "- Un **evento real extremo** (una atención costosa)\n",
    "- Un **sub-proceso diferente** (reembolsos: valores negativos esperados)\n",
    "\n",
    "Aquí tomaremos decisiones típicas de negocio:\n",
    "\n",
    "1. **Edad**: marcar valores fuera de rango y corregir a `NaN` para no distorsionar.\n",
    "2. **Satisfacción**: forzar rango 1–10 y dejar `NaN` si es inválido.\n",
    "3. **Montos**: usar *capping* (winsorization) en p99 para análisis agregado.\n",
    "4. **Reembolsos**: NO mezclarlos como “outliers”; tratarlos como categoría separada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.2 A) Limpieza por reglas de negocio (edad y satisfacción)\n",
    "# ============================================================\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Edad válida: 18 a 90 (lo demás lo marcamos como NaN)\n",
    "df_clean[\"age_clean\"] = df_clean[\"age\"].where(df_clean[\"age\"].between(18, 90), np.nan)\n",
    "\n",
    "# Satisfacción válida: 1 a 10 (lo demás NaN)\n",
    "df_clean[\"satisfaction_clean\"] = df_clean[\"satisfaction_score\"].where(df_clean[\"satisfaction_score\"].between(1, 10), np.nan)\n",
    "\n",
    "print(\"Edad inválida:\", df_clean[\"age_clean\"].isna().sum(), \"de\", len(df_clean))\n",
    "print(\"Satisfacción inválida:\", df_clean[\"satisfaction_clean\"].isna().sum(), \"de\", len(df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.2 B) Capping de montos para análisis (p99 sobre ingresos)\n",
    "# ============================================================\n",
    "\n",
    "p99 = df_clean.loc[df_clean[\"amount_net\"] > 0, \"amount_net\"].quantile(0.99)\n",
    "\n",
    "df_clean[\"amount_net_capped\"] = df_clean[\"amount_net\"].copy()\n",
    "\n",
    "# Solo capear ingresos (no tocar reembolsos)\n",
    "mask_revenue = df_clean[\"amount_net_capped\"] > 0\n",
    "df_clean.loc[mask_revenue, \"amount_net_capped\"] = df_clean.loc[mask_revenue, \"amount_net_capped\"].clip(upper=p99)\n",
    "\n",
    "print(\"p99 amount_net (ingresos):\", p99)\n",
    "df_clean.loc[mask_revenue, [\"amount_net\",\"amount_net_capped\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar distribución antes/después (ingresos)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df_clean.loc[mask_revenue, \"amount_net\"], bins=50)\n",
    "plt.title(\"amount_net (antes) - solo ingresos\")\n",
    "plt.xlabel(\"amount_net\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df_clean.loc[mask_revenue, \"amount_net_capped\"], bins=50)\n",
    "plt.title(\"amount_net_capped (después) - solo ingresos\")\n",
    "plt.xlabel(\"amount_net_capped\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.3 · Segmentación de clientes con sentencias `if/elif/else` (proyecto)\n",
    "\n",
    "Vamos a crear una segmentación simple tipo RFM:\n",
    "\n",
    "- **Recency** (días desde la última visita)\n",
    "- **Frequency** (num_visits)\n",
    "- **Monetary** (total_spend)\n",
    "\n",
    "Objetivo: producir una columna `segment_if` con categorías accionables:\n",
    "- `VIP`\n",
    "- `Leal`\n",
    "- `Prometedor`\n",
    "- `En riesgo`\n",
    "- `Bajo valor`\n",
    "\n",
    "Regla importante: la segmentación debe ser **explicable** y **reproducible**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.3 Segmentación con if/elif/else\n",
    "# ============================================================\n",
    "\n",
    "# Reconstruimos métricas usando df_clean (para usar montos cappeados si queremos)\n",
    "df_rev_clean = df_clean[df_clean[\"amount_net_capped\"] > 0].copy()\n",
    "\n",
    "as_of_date = df_clean[\"appointment_date\"].max()\n",
    "\n",
    "customer_metrics2 = (\n",
    "    df_clean.groupby(\"customer_id\")\n",
    "      .agg(\n",
    "          num_visits=(\"transaction_id\",\"nunique\"),\n",
    "          total_spend=(\"amount_net_capped\", lambda s: s[s>0].sum()),\n",
    "          last_visit_date=(\"appointment_date\",\"max\"),\n",
    "          avg_satisfaction=(\"satisfaction_clean\",\"mean\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "customer_metrics2[\"recency_days\"] = (as_of_date - customer_metrics2[\"last_visit_date\"]).dt.days\n",
    "\n",
    "# Umbrales simples (pueden ajustarse)\n",
    "p75_spend = customer_metrics2[\"total_spend\"].quantile(0.75)\n",
    "p75_visits = customer_metrics2[\"num_visits\"].quantile(0.75)\n",
    "\n",
    "def segment_customer_if(row: pd.Series) -> str:\n",
    "    \"\"\"Asigna un segmento basado en reglas RFM sencillas.\n",
    "\n",
    "    Nota pedagógica: se usa if/elif/else para que sea claro y fácil de explicar.\n",
    "    \"\"\"\n",
    "    recency = row[\"recency_days\"]\n",
    "    freq = row[\"num_visits\"]\n",
    "    monetary = row[\"total_spend\"]\n",
    "    sat = row[\"avg_satisfaction\"]\n",
    "\n",
    "    # VIP: reciente, frecuente y alto gasto\n",
    "    if (recency <= 30) and (freq >= p75_visits) and (monetary >= p75_spend):\n",
    "        return \"VIP\"\n",
    "\n",
    "    # Leal: frecuente y relativamente reciente\n",
    "    elif (recency <= 60) and (freq >= p75_visits):\n",
    "        return \"Leal\"\n",
    "\n",
    "    # Prometedor: reciente pero con menos frecuencia (o gasto moderado)\n",
    "    elif (recency <= 30) and (freq < p75_visits):\n",
    "        return \"Prometedor\"\n",
    "\n",
    "    # En riesgo: no ha venido hace tiempo pero antes tuvo actividad\n",
    "    elif (recency > 90) and (freq >= 3):\n",
    "        return \"En riesgo\"\n",
    "\n",
    "    # Bajo valor: poca frecuencia y poco gasto\n",
    "    else:\n",
    "        return \"Bajo valor\"\n",
    "\n",
    "customer_metrics2[\"segment_if\"] = customer_metrics2.apply(segment_customer_if, axis=1)\n",
    "\n",
    "customer_metrics2[\"segment_if\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.4 · Segmentación con `apply()` y funciones que integran IF para crear nuevas columnas\n",
    "\n",
    "En proyectos reales, el “segmento” no es lo único que necesitamos.  \n",
    "Frecuentemente creamos **múltiples variables** para activar acciones:\n",
    "\n",
    "- `needs_follow_up` (¿requiere seguimiento?)\n",
    "- `discount_eligible` (¿es elegible a incentivo?)\n",
    "- `recommended_channel` (¿por dónde contactarlo?)\n",
    "\n",
    "Vamos a construir una función que retorna un `pd.Series` con varias columnas nuevas y la aplicaremos con `apply()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.4 apply() para crear varias columnas\n",
    "# ============================================================\n",
    "\n",
    "def enrichment_rules(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"Reglas de enriquecimiento (múltiples flags) basadas en condiciones.\n",
    "\n",
    "    Retorna un pd.Series con varias columnas:\n",
    "    - needs_follow_up\n",
    "    - discount_eligible\n",
    "    - recommended_channel\n",
    "    \"\"\"\n",
    "    recency = row[\"recency_days\"]\n",
    "    seg = row[\"segment_if\"]\n",
    "    sat = row[\"avg_satisfaction\"]\n",
    "\n",
    "    # 1) needs_follow_up: alto recency o satisfacción baja\n",
    "    if (recency > 90) or (pd.notna(sat) and sat <= 6):\n",
    "        needs_follow_up = 1\n",
    "    else:\n",
    "        needs_follow_up = 0\n",
    "\n",
    "    # 2) discount_eligible: segmento “En riesgo” o “Bajo valor” con cierta actividad\n",
    "    if seg in [\"En riesgo\", \"Bajo valor\"] and row[\"num_visits\"] >= 2:\n",
    "        discount_eligible = 1\n",
    "    else:\n",
    "        discount_eligible = 0\n",
    "\n",
    "    # 3) recommended_channel: por defecto Email, pero si recency muy alto -> Call Center\n",
    "    if recency > 120:\n",
    "        recommended_channel = \"Call Center\"\n",
    "    else:\n",
    "        recommended_channel = \"Email\"\n",
    "\n",
    "    return pd.Series({\n",
    "        \"needs_follow_up\": needs_follow_up,\n",
    "        \"discount_eligible\": discount_eligible,\n",
    "        \"recommended_channel\": recommended_channel\n",
    "    })\n",
    "\n",
    "enriched = customer_metrics2.apply(enrichment_rules, axis=1)\n",
    "customer_metrics2 = pd.concat([customer_metrics2, enriched], axis=1)\n",
    "\n",
    "display(customer_metrics2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-ejercicio (5 min)\n",
    "\n",
    "1. Crea una columna `priority` con estos valores:\n",
    "   - `Alta` si `needs_follow_up == 1` y `discount_eligible == 1`\n",
    "   - `Media` si `needs_follow_up == 1` y `discount_eligible == 0`\n",
    "   - `Baja` en cualquier otro caso\n",
    "\n",
    "Hazlo de dos maneras:\n",
    "- (A) con `if/elif/else` en una función\n",
    "- (B) con `np.select`\n",
    "\n",
    "Compara cuál te parece más legible para un equipo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución (Mini-ejercicio)\n",
    "\n",
    "def priority_if(row):\n",
    "    if (row[\"needs_follow_up\"] == 1) and (row[\"discount_eligible\"] == 1):\n",
    "        return \"Alta\"\n",
    "    elif (row[\"needs_follow_up\"] == 1) and (row[\"discount_eligible\"] == 0):\n",
    "        return \"Media\"\n",
    "    else:\n",
    "        return \"Baja\"\n",
    "\n",
    "customer_metrics2[\"priority_if\"] = customer_metrics2.apply(priority_if, axis=1)\n",
    "\n",
    "conditions = [\n",
    "    (customer_metrics2[\"needs_follow_up\"] == 1) & (customer_metrics2[\"discount_eligible\"] == 1),\n",
    "    (customer_metrics2[\"needs_follow_up\"] == 1) & (customer_metrics2[\"discount_eligible\"] == 0),\n",
    "]\n",
    "choices = [\"Alta\", \"Media\"]\n",
    "\n",
    "customer_metrics2[\"priority_npselect\"] = np.select(conditions, choices, default=\"Baja\")\n",
    "\n",
    "customer_metrics2[[\"priority_if\",\"priority_npselect\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.5 · Redacción de un Statistical Summary (proyecto)\n",
    "\n",
    "Un Statistical Summary es un texto corto (1–2 páginas) que:\n",
    "\n",
    "1. Resume el dataset (tamaño, cobertura temporal).\n",
    "2. Describe hallazgos clave (KPIs, distribuciones).\n",
    "3. Documenta decisiones (tratamiento de outliers, supuestos).\n",
    "4. Entrega conclusiones y próximos pasos.\n",
    "\n",
    "Aquí crearemos una **plantilla automática** que toma métricas calculadas y genera un borrador en Markdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.5 Generar un Statistical Summary en Markdown\n",
    "# ============================================================\n",
    "\n",
    "# KPIs globales\n",
    "n_rows = len(df_clean)\n",
    "n_customers = df_clean[\"customer_id\"].nunique()\n",
    "\n",
    "date_min = df_clean[\"appointment_date\"].min().date()\n",
    "date_max = df_clean[\"appointment_date\"].max().date()\n",
    "\n",
    "refund_rate_global = (df_clean[\"amount_net\"] < 0).mean()\n",
    "avg_ticket_global = df_clean.loc[df_clean[\"amount_net_capped\"] > 0, \"amount_net_capped\"].mean()\n",
    "\n",
    "# Distribución de segmentos\n",
    "segment_dist = customer_metrics2[\"segment_if\"].value_counts(normalize=True).round(4)\n",
    "\n",
    "summary_md = f\"\"\"# Statistical Summary · Clínica Agendada\n",
    "\n",
    "## 1. Dataset\n",
    "- Filas (transacciones/citas): **{n_rows:,}**\n",
    "- Clientes únicos: **{n_customers:,}**\n",
    "- Ventana temporal: **{date_min} → {date_max}**\n",
    "\n",
    "## 2. Calidad y preparación\n",
    "- Se crearon columnas limpias:\n",
    "  - `age_clean` (edad válida 18–90; inválidos a NaN)\n",
    "  - `satisfaction_clean` (rango 1–10; inválidos a NaN)\n",
    "- Para análisis de montos, se aplicó *capping* en p99 sobre ingresos (no reembolsos):\n",
    "  - `amount_net_capped`\n",
    "\n",
    "## 3. Hallazgos (KPIs)\n",
    "- Tasa global de reembolsos (por transacción): **{refund_rate_global:.2%}**\n",
    "- Ticket promedio (ingresos cappeados): **{avg_ticket_global:,.0f}**\n",
    "\n",
    "## 4. Segmentación (RFM simplificado)\n",
    "Distribución de segmentos (proporción de clientes):\n",
    "{segment_dist.to_string()}\n",
    "\n",
    "## 5. Recomendaciones\n",
    "- Revisar outliers de espera (`wait_time_min`) para identificar cuellos de botella.\n",
    "- Diseñar campañas por segmento:\n",
    "  - VIP: beneficios premium / cross-sell\n",
    "  - En riesgo: follow-up + incentivo controlado\n",
    "  - Bajo valor: onboarding + educación del servicio\n",
    "\n",
    "## 6. Próximos pasos\n",
    "- Validar reglas con stakeholders (operaciones, finanzas).\n",
    "- A/B test de incentivos por segmento.\n",
    "\"\"\"\n",
    "\n",
    "# Guardar el summary como artefacto de proyecto\n",
    "summary_file = OUTPUTS_DIR / \"statistical_summary.md\"\n",
    "summary_file.write_text(summary_md, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Resumen guardado en: {summary_file}\")\n",
    "print(summary_md[:600] + \"\\n...\")  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 · Almacenando y compartiendo análisis (publicación en GitHub)\n",
    "\n",
    "En un proyecto real, tu análisis debe ser:\n",
    "- **Reproducible** (otros pueden correrlo)\n",
    "- **Versionado** (historial de cambios)\n",
    "- **Compartible** (enlace a repo + README)\n",
    "\n",
    "En este bloque vamos a:\n",
    "1. Guardar artefactos (`outputs/`, `figures/`).\n",
    "2. Crear `README.md` mínimo.\n",
    "3. Inicializar repo Git, hacer commits y preparar el push a GitHub.\n",
    "4. Ver el workflow típico en Google Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.4 A) Guardar outputs del proyecto\n",
    "# ============================================================\n",
    "\n",
    "# Guardar métricas por cliente\n",
    "customer_metrics_file = OUTPUTS_DIR / \"customer_metrics.csv\"\n",
    "customer_metrics2.to_csv(customer_metrics_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Archivo guardado: {customer_metrics_file} | filas={len(customer_metrics2):,}\")\n",
    "\n",
    "# (Opcional) Guardar un gráfico como figura\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(customer_metrics2[\"total_spend\"], bins=50)\n",
    "plt.title(\"Distribución de total_spend por cliente (cappeado)\")\n",
    "plt.xlabel(\"total_spend\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "\n",
    "fig_path = FIG_DIR / \"total_spend_hist.png\"\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Figura guardada: {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.4 B) Crear README.md y (opcional) requirements.txt\n",
    "# ============================================================\n",
    "\n",
    "readme_file = Path(\"README.md\")\n",
    "if not readme_file.exists():\n",
    "    readme_file.write_text(\"\"\"# Proyecto · Clínica Agendada (Sprint 7)\n",
    "\n",
    "Este repositorio contiene un proyecto práctico de Data Analytics para:\n",
    "\n",
    "- Analizar calidad de datos y EDA\n",
    "- Detectar y tratar outliers (IQR/Z-score + contexto de negocio)\n",
    "- Construir métricas por cliente (RFM simplificado)\n",
    "- Segmentar clientes (if + apply)\n",
    "- Redactar un Statistical Summary\n",
    "\n",
    "## Estructura\n",
    "\n",
    "- `data/clinic_transactions.csv`: dataset (sintético)\n",
    "- `notebooks/`: notebook del proyecto\n",
    "- `outputs/`: métricas y summary\n",
    "- `figures/`: gráficos exportados\n",
    "\n",
    "## Cómo ejecutar\n",
    "\n",
    "1. Crear entorno (recomendado): `python -m venv .venv`\n",
    "2. Instalar dependencias: `pip install -r requirements.txt`\n",
    "3. Abrir y ejecutar el notebook.\n",
    "\n",
    "## Resultados principales\n",
    "\n",
    "Ver `outputs/statistical_summary.md`.\n",
    "\"\"\", encoding=\"utf-8\")\n",
    "    print(\"README.md creado.\")\n",
    "else:\n",
    "    print(\"README.md ya existe (no se sobreescribió).\")\n",
    "\n",
    "requirements_file = Path(\"requirements.txt\")\n",
    "if not requirements_file.exists():\n",
    "    requirements_file.write_text(\"\\n\".join([\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"matplotlib\"\n",
    "    ]) + \"\\n\", encoding=\"utf-8\")\n",
    "    print(\"requirements.txt creado.\")\n",
    "else:\n",
    "    print(\"requirements.txt ya existe (no se sobreescribió).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1–7.4.3 · GitHub para analistas + estructura de repos + workflow con Colab\n",
    "\n",
    "A continuación tienes comandos típicos para publicar tu proyecto.\n",
    "\n",
    "> Nota: estos comandos se ejecutan en terminal.  \n",
    "> En Jupyter/Colab puedes ejecutarlos con `!` al inicio.\n",
    "\n",
    "#### Paso 1: Crear estructura de repo (sugerida)\n",
    "\n",
    "```\n",
    "project/\n",
    "  data/\n",
    "  notebooks/\n",
    "  outputs/\n",
    "  figures/\n",
    "  README.md\n",
    "  requirements.txt\n",
    "  .gitignore\n",
    "```\n",
    "\n",
    "#### Paso 2: Inicializar git y primer commit\n",
    "\n",
    "```\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial commit: project skeleton + dataset + notebook\"\n",
    "```\n",
    "\n",
    "#### Paso 3: Crear repo en GitHub y agregar remote\n",
    "\n",
    "En GitHub: New repository → copia la URL (HTTPS).\n",
    "\n",
    "```\n",
    "git remote add origin https://github.com/<TU_USUARIO>/<TU_REPO>.git\n",
    "git branch -M main\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "#### Paso 4: Workflow recomendado (GitHub Flow)\n",
    "\n",
    "- Crea branch por cambio: `git checkout -b feature/segmentacion`\n",
    "- Commits pequeños y descriptivos\n",
    "- Pull Request → revisión → merge\n",
    "\n",
    "#### En Google Colab (workflow típico)\n",
    "1. Conecta Google Drive (opcional).\n",
    "2. Clona tu repo: `!git clone https://github.com/<TU_USUARIO>/<TU_REPO>.git`\n",
    "3. Ejecuta el notebook, genera outputs.\n",
    "4. Commit y push desde Colab (requiere autenticación/token).\n",
    "\n",
    "**Tip:** evita subir datos sensibles. En este proyecto el dataset es sintético, así que está OK subirlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "- La detección de outliers (IQR/Z-score) es el **inicio**, no el final: el contexto define la acción.\n",
    "- Segmentación efectiva = reglas **claras**, variables agregadas y trazabilidad.\n",
    "- Un buen Statistical Summary documenta **métricas + decisiones + supuestos**.\n",
    "- Publicar en GitHub vuelve tu análisis **reproducible** y facilita colaboración.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cierre\n",
    "**Kahoot de repaso (5 min)**\n",
    "- Trabajamos en el proyecto \"Clínica Agendada\" de principio a fin.\n",
    "- Generamos datos, limpiamos y detectamos segmentos.\n",
    "\n",
    "**Reflexión:**\n",
    "- ¿Qué fue lo más retador de integrar todas las habilidades (Python + Stats + Git)?\n",
    "- ¿Cómo explicarías tus hallazgos a un director médico no técnico?\n",
    "\n",
    "**Q&A y próximos pasos.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siguientes Pasos\n",
    "- **Próxima sesión:** Sprint 8 - Correlaciones y Relaciones entre variables.\n",
    "- **Participación:** Completa el README de tu repositorio en GitHub.\n",
    "- **Recordatorios:** Entrega el link de tu repo en la plataforma.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
