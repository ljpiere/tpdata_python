{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 7 · Webinar 22 · Data Analytics práctico (Proyecto: outliers, segmentación y GitHub)\n",
    "\n",
    "**Duración:** 100 minutos  \n",
    "**Modalidad:** Práctica guiada (proyecto paso a paso)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fecha\n",
    "\n",
    "Completa la información de la sesión:\n",
    "\n",
    "- **Fecha:**  \n",
    "- **Instructor/a:**  \n",
    "- **Duración:** 100 minutos  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos de la sesión práctica\n",
    "\n",
    "Al finalizar esta sesión, la persona estudiante será capaz de:\n",
    "\n",
    "1. **Generar y documentar** un dataset sintético realista (CSV) para un proyecto práctico.\n",
    "2. Realizar **carga, limpieza y exploración** de datos (tipos, nulos, duplicados, calidad).\n",
    "3. Construir **métricas por cliente** (agregaciones tipo RFM y KPIs operativos).\n",
    "4. **Detectar y tratar valores atípicos** usando reglas estadísticas (IQR/Z-score) y criterio de negocio.\n",
    "5. Crear **segmentos de clientes** con `if/elif/else` y con `apply()` usando funciones personalizadas.\n",
    "6. Redactar un **Statistical Summary** (hallazgos clave + métricas + decisiones tomadas).\n",
    "7. Empaquetar, versionar y **publicar el proyecto en GitHub** (estructura de repo + workflow).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda sugerida (100 minutos)\n",
    "\n",
    "| Tiempo | Bloque | Contenido | Modalidad |\n",
    "|---:|---|---|---|\n",
    "| 10 min | Contexto del proyecto | Caso de uso, entregables y dataset | Guía |\n",
    "| 15 min | Dataset (CSV) + carga | Generación, diccionario de datos, lectura | Live coding |\n",
    "| 20 min | Calidad + EDA | Tipos, nulos, duplicados, distribuciones | Ejercicio guiado |\n",
    "| 20 min | Métricas por cliente | Agregaciones y KPIs (RFM básico) | Ejercicio guiado |\n",
    "| 20 min | Outliers | Detección (IQR/Z) + tratamiento por contexto | Ejercicio guiado |\n",
    "| 10 min | Segmentación | `if` + `apply()` con función | Ejercicio guiado |\n",
    "| 5 min | Statistical Summary | Plantilla + texto basado en KPIs | Guía |\n",
    "| 10 min | Publicación en GitHub | Estructura, commits, push, Colab workflow | Guía práctica |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 0 · Kickoff del proyecto (5 min)\n",
    "\n",
    "En parejas (o individual), responde:\n",
    "\n",
    "1. ¿Qué decisiones de negocio podríamos tomar con estos datos?\n",
    "2. ¿Qué variables crees que tendrán outliers y por qué?\n",
    "3. ¿Qué significa “segmento” para ti en este contexto (retención, VIP, riesgo)?\n",
    "\n",
    "**Salida esperada:** 3–5 bullets con hipótesis iniciales.  \n",
    "Luego validaremos (o corregiremos) esas hipótesis con datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto práctico: “Clínica Agendada” (Customer Analytics)\n",
    "\n",
    "Vas a trabajar como analista en una empresa que ofrece servicios de salud bajo agenda. El negocio quiere responder:\n",
    "\n",
    "- ¿Cómo se comportan los clientes por plan, canal y ciudad?\n",
    "- ¿Qué tan frecuentes son los **reembolsos** y cómo afectan los ingresos?\n",
    "- ¿Existen **valores atípicos** (montos, tiempos de espera, edades) que distorsionen el análisis?\n",
    "- ¿Podemos **segmentar** clientes para acciones (retención, cross-sell, incentivos)?\n",
    "\n",
    "### Entregables del proyecto (lo que publicaremos en GitHub)\n",
    "1. Un dataset **en CSV** (generado en el notebook).\n",
    "2. Un notebook reproducible con:\n",
    "   - Limpieza + EDA\n",
    "   - Detección y tratamiento de outliers\n",
    "   - Segmentación (if + apply)\n",
    "   - Statistical Summary\n",
    "3. Artefactos en el repo:\n",
    "   - `README.md`\n",
    "   - `data/clinic_transactions.csv`\n",
    "   - `outputs/customer_metrics.csv`\n",
    "   - `outputs/statistical_summary.md`\n",
    "   - `figures/` (opcional: gráficos exportados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diccionario de datos (CSV)\n",
    "\n",
    "El archivo contiene **transacciones / citas** (1 fila = 1 cita facturada o reembolsada) con atributos del cliente.\n",
    "\n",
    "| Columna | Tipo | Descripción |\n",
    "|---|---|---|\n",
    "| `transaction_id` | str | ID único de la transacción |\n",
    "| `customer_id` | str | ID del cliente |\n",
    "| `appointment_date` | datetime | Fecha de la cita/transacción |\n",
    "| `service_type` | category | Tipo de servicio (consulta, laboratorio, etc.) |\n",
    "| `appointment_channel` | category | Canal de agenda (Web/App/Call Center/Presencial) |\n",
    "| `payment_method` | category | Método de pago |\n",
    "| `amount_gross` | float | Valor bruto antes de descuentos |\n",
    "| `discount_pct` | int | % de descuento aplicado |\n",
    "| `amount_net` | float | Valor neto (negativo si es reembolso) |\n",
    "| `is_refund` | int | 1 si es reembolso, 0 si no |\n",
    "| `refund_reason` | str | Motivo de reembolso (si aplica) |\n",
    "| `wait_time_min` | float | Tiempo de espera (minutos) |\n",
    "| `service_duration_min` | float | Duración del servicio (minutos) |\n",
    "| `satisfaction_score` | float | Satisfacción (esperado 1–10; contiene nulos/outliers) |\n",
    "| `signup_date` | datetime | Fecha de registro del cliente |\n",
    "| `age` | int | Edad (contiene valores sucios/outliers) |\n",
    "| `gender` | category | Género (F/M/X) |\n",
    "| `city` | category | Ciudad |\n",
    "| `acquisition_channel` | category | Canal de adquisición |\n",
    "| `plan` | category | Plan (Básico/Plus/Premium) |\n",
    "| `has_insurance` | int | 1 si tiene seguro, 0 si no |\n",
    "| `is_revenue` | int | 1 si `amount_net` > 0 (ingreso), 0 si no |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0) Setup del proyecto\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (Opcional) Para ver más columnas en pantalla\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# (Opcional) Semilla para reproducibilidad\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "print(\"Entorno listo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 · Generar el dataset sintético (CSV)\n",
    "\n",
    "En proyectos reales, a veces necesitas **simular datos** para probar análisis, dashboards o pipelines.\n",
    "\n",
    "En este ejercicio:\n",
    "- Generaremos un dataset realista de transacciones (citas) y lo guardaremos como CSV.\n",
    "- Luego trabajaremos **solo** a partir del CSV (como en un proyecto real).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Generación del dataset y export a CSV\n",
    "# ============================================================\n",
    "\n",
    "def generate_clinic_dataset(\n",
    "    n_customers: int = 5000,\n",
    "    target_rows: int = 40000,\n",
    "    seed: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Genera un dataset sintético de transacciones (citas) + atributos de cliente.\n",
    "\n",
    "    El objetivo es tener un dataset suficientemente grande para practicar:\n",
    "    - EDA y calidad de datos\n",
    "    - Outliers (montos, tiempos, edades, satisfacción)\n",
    "    - Segmentación de clientes\n",
    "    \"\"\"\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "\n",
    "    # ----------------------------\n",
    "    # A) Tabla de clientes\n",
    "    # ----------------------------\n",
    "    customer_ids = [f\"C{str(i).zfill(5)}\" for i in range(1, n_customers + 1)]\n",
    "\n",
    "    cities = [\n",
    "        \"Bogotá\",\"Medellín\",\"Cali\",\"Barranquilla\",\"Cartagena\",\n",
    "        \"Bucaramanga\",\"Pereira\",\"Manizales\",\"Santa Marta\",\"Cúcuta\"\n",
    "    ]\n",
    "    channels = [\"Organic\",\"Paid Search\",\"Paid Social\",\"Referral\",\"Partners\",\"Email\",\"Direct\"]\n",
    "    plans = [\"Básico\",\"Plus\",\"Premium\"]\n",
    "    genders = [\"F\",\"M\",\"X\"]\n",
    "\n",
    "    signup_start = np.datetime64(\"2023-01-01\", \"D\")\n",
    "    signup_end = np.datetime64(\"2025-12-31\", \"D\")\n",
    "    signup_days = int((signup_end - signup_start).astype(int))\n",
    "\n",
    "    signup_dates = signup_start + rng_local.integers(0, signup_days + 1, size=n_customers).astype(\"timedelta64[D]\")\n",
    "\n",
    "    ages = rng_local.normal(36, 12, size=n_customers).round().astype(int)\n",
    "    ages = np.clip(ages, 18, 85)\n",
    "\n",
    "    # Inyectar outliers de edad (~1%)\n",
    "    outlier_idx = rng_local.choice(n_customers, size=int(0.01 * n_customers), replace=False)\n",
    "    half = len(outlier_idx) // 2\n",
    "    ages[outlier_idx[:half]] = rng_local.integers(5, 15, size=half)                  # edades demasiado bajas\n",
    "    ages[outlier_idx[half:]] = rng_local.integers(95, 120, size=len(outlier_idx)-half) # edades demasiado altas\n",
    "\n",
    "    customers = pd.DataFrame({\n",
    "        \"customer_id\": customer_ids,\n",
    "        \"signup_date\": pd.to_datetime(signup_dates.astype(\"datetime64[D]\")),\n",
    "        \"age\": ages,\n",
    "        \"gender\": rng_local.choice(genders, size=n_customers, p=[0.48, 0.48, 0.04]),\n",
    "        \"city\": rng_local.choice(cities, size=n_customers, p=[0.28,0.18,0.14,0.08,0.06,0.07,0.06,0.05,0.04,0.04]),\n",
    "        \"acquisition_channel\": rng_local.choice(channels, size=n_customers, p=[0.28,0.18,0.12,0.14,0.08,0.12,0.08]),\n",
    "        \"plan\": rng_local.choice(plans, size=n_customers, p=[0.55,0.30,0.15]),\n",
    "        \"has_insurance\": rng_local.choice([0, 1], size=n_customers, p=[0.6, 0.4])\n",
    "    })\n",
    "\n",
    "    # ----------------------------\n",
    "    # B) Tabla de transacciones/citas\n",
    "    # ----------------------------\n",
    "    service_types = [\"Consulta general\",\"Especialista\",\"Odontología\",\"Laboratorio\",\"Imágenes\",\"Urgencias\",\"Terapia\"]\n",
    "    base_price = {\n",
    "        \"Consulta general\": 45000,\n",
    "        \"Especialista\": 90000,\n",
    "        \"Odontología\": 120000,\n",
    "        \"Laboratorio\": 65000,\n",
    "        \"Imágenes\": 150000,\n",
    "        \"Urgencias\": 200000,\n",
    "        \"Terapia\": 70000\n",
    "    }\n",
    "    payment_methods = [\"Tarjeta\",\"Transferencia\",\"Efectivo\",\"PSE\",\"Débito\"]\n",
    "    appointment_channels = [\"Web\",\"App\",\"Call Center\",\"Presencial\"]\n",
    "\n",
    "    # Número de transacciones por cliente (ajustado para llegar a target_rows)\n",
    "    tx_counts = rng_local.poisson(lam=max(target_rows / n_customers, 1.0), size=n_customers) + 1\n",
    "    scale = target_rows / tx_counts.sum()\n",
    "    tx_counts = np.maximum(1, (tx_counts * scale).round().astype(int))\n",
    "\n",
    "    # Ajuste fino para lograr exactamente target_rows filas\n",
    "    diff = target_rows - int(tx_counts.sum())\n",
    "    if diff != 0:\n",
    "        idxs = rng_local.choice(n_customers, size=abs(diff), replace=True)\n",
    "        for i in idxs:\n",
    "            tx_counts[i] += 1 if diff > 0 else -1\n",
    "            tx_counts[i] = max(tx_counts[i], 1)\n",
    "\n",
    "    end_date = np.datetime64(\"2025-12-31\", \"D\")\n",
    "    rows = []\n",
    "    tx_id = 1\n",
    "\n",
    "    for i, cid in enumerate(customer_ids):\n",
    "        k = int(tx_counts[i])\n",
    "\n",
    "        # Fecha de cita entre signup y end_date\n",
    "        signup = np.datetime64(customers.loc[i, \"signup_date\"].date(), \"D\")\n",
    "        max_day = int((end_date - signup).astype(int))\n",
    "        day_offsets = rng_local.integers(0, max_day + 1 if max_day > 0 else 1, size=k).astype(\"timedelta64[D]\")\n",
    "        appointment_dates = signup + day_offsets\n",
    "\n",
    "        stypes = rng_local.choice(service_types, size=k, p=[0.28,0.20,0.12,0.16,0.10,0.06,0.08])\n",
    "\n",
    "        plan = customers.loc[i, \"plan\"]\n",
    "        plan_mult = {\"Básico\": 1.00, \"Plus\": 1.05, \"Premium\": 1.10}[plan]\n",
    "\n",
    "        # Precio con distribución sesgada (lognormal)\n",
    "        amounts = np.array([base_price[s] for s in stypes], dtype=float) * plan_mult\n",
    "        amounts *= rng_local.lognormal(mean=0.0, sigma=0.25, size=k)\n",
    "        amounts = np.round(amounts, 0)\n",
    "\n",
    "        discount_pct = rng_local.choice([0,5,10,15,20,30], size=k, p=[0.55,0.12,0.12,0.08,0.08,0.05])\n",
    "        net_amount = np.round(amounts * (1 - discount_pct / 100.0), 0)\n",
    "\n",
    "        # Reembolsos (~2.5%): net_amount negativo\n",
    "        is_refund = rng_local.choice([0,1], size=k, p=[0.975,0.025])\n",
    "        refund_reason = np.where(\n",
    "            is_refund == 1,\n",
    "            rng_local.choice([\"Duplicado\",\"Error de facturación\",\"No asistió\",\"Servicio no prestado\"], size=k),\n",
    "            \"\"\n",
    "        )\n",
    "        net_amount = np.where(is_refund == 1, -net_amount, net_amount)\n",
    "\n",
    "        # Satisfacción 1–10, algunos nulos, algunos outliers (0,11,12)\n",
    "        satisfaction = np.round(rng_local.normal(8.2, 1.4, size=k), 0)\n",
    "        satisfaction = np.clip(satisfaction, 1, 10).astype(float)\n",
    "        satisfaction[rng_local.random(size=k) < 0.08] = np.nan  # nulos\n",
    "\n",
    "        outlier_sat = rng_local.random(size=k) < 0.003\n",
    "        satisfaction[outlier_sat] = rng_local.choice([0, 11, 12], size=outlier_sat.sum())\n",
    "\n",
    "        # Variables operativas (tiempos)\n",
    "        wait_time = rng_local.gamma(shape=2.2, scale=12, size=k)      # media ~26\n",
    "        duration = rng_local.normal(35, 12, size=k)\n",
    "\n",
    "        wait_time = np.clip(wait_time, 1, 180)\n",
    "        duration = np.clip(duration, 5, 120)\n",
    "\n",
    "        # Inyectar outliers de espera (muy altos)\n",
    "        outlier_wait = rng_local.random(size=k) < 0.002\n",
    "        wait_time[outlier_wait] = rng_local.integers(240, 900, size=outlier_wait.sum())\n",
    "\n",
    "        ap_channel = rng_local.choice(appointment_channels, size=k, p=[0.30,0.38,0.18,0.14])\n",
    "        pay_method = rng_local.choice(payment_methods, size=k, p=[0.34,0.16,0.10,0.28,0.12])\n",
    "\n",
    "        for j in range(k):\n",
    "            rows.append({\n",
    "                \"transaction_id\": f\"T{tx_id:07d}\",\n",
    "                \"customer_id\": cid,\n",
    "                \"appointment_date\": pd.Timestamp(appointment_dates[j].astype(\"datetime64[D]\")),\n",
    "                \"service_type\": stypes[j],\n",
    "                \"appointment_channel\": ap_channel[j],\n",
    "                \"payment_method\": pay_method[j],\n",
    "                \"amount_gross\": float(amounts[j]),\n",
    "                \"discount_pct\": int(discount_pct[j]),\n",
    "                \"amount_net\": float(net_amount[j]),\n",
    "                \"is_refund\": int(is_refund[j]),\n",
    "                \"refund_reason\": refund_reason[j],\n",
    "                \"wait_time_min\": float(wait_time[j]),\n",
    "                \"service_duration_min\": float(duration[j]),\n",
    "                \"satisfaction_score\": satisfaction[j]\n",
    "            })\n",
    "            tx_id += 1\n",
    "\n",
    "    tx = pd.DataFrame(rows)\n",
    "\n",
    "    # Denormalizar (un CSV único)\n",
    "    df = tx.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "    # Inyectar un pequeño % de edades “sucias” para simular errores de captura\n",
    "    dirty_age = rng_local.random(size=len(df)) < 0.001\n",
    "    df.loc[dirty_age, \"age\"] = rng_local.choice([-3, 0, 150, 999], size=dirty_age.sum())\n",
    "\n",
    "    # Bandera: ingreso (amount_net > 0)\n",
    "    df[\"is_revenue\"] = np.where(df[\"amount_net\"] > 0, 1, 0)\n",
    "\n",
    "    # Mezclar filas\n",
    "    df = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Rutas del proyecto (estructura típica de repo)\n",
    "DATA_DIR = Path(\"data\")\n",
    "OUTPUTS_DIR = Path(\"outputs\")\n",
    "FIG_DIR = Path(\"figures\")\n",
    "\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "csv_file = DATA_DIR / \"clinic_transactions.csv\"\n",
    "\n",
    "# Generar solo si no existe (para no sobreescribir si ya lo tienes)\n",
    "if not csv_file.exists():\n",
    "    df_generated = generate_clinic_dataset(n_customers=5000, target_rows=40000, seed=RANDOM_SEED)\n",
    "    df_generated.to_csv(csv_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"CSV generado: {csv_file} | filas={len(df_generated):,}\")\n",
    "else:\n",
    "    print(f\"El CSV ya existe: {csv_file}\")\n",
    "\n",
    "# Vista rápida (si acabamos de generar, df_generated existe; si no, lo cargamos)\n",
    "df_preview = pd.read_csv(csv_file)\n",
    "df_preview.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 · Cargar el CSV y revisar calidad de datos (EDA rápido)\n",
    "\n",
    "En un proyecto real, lo primero es responder:\n",
    "\n",
    "- ¿Cuántas filas/columnas tenemos?\n",
    "- ¿Hay valores nulos? ¿En qué columnas?\n",
    "- ¿Hay duplicados?\n",
    "- ¿Los tipos de datos (fechas/números) son correctos?\n",
    "\n",
    "**Meta:** terminar con un dataframe listo para análisis (con tipos correctos y flags útiles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) Cargar CSV y EDA rápido\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# Tipos de datos actuales\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisión de nulos y duplicados\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "display(missing.head(10))\n",
    "\n",
    "print(\"Duplicados (filas completas):\", df.duplicated().sum())\n",
    "print(\"Duplicados por transaction_id:\", df[\"transaction_id\"].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a datetime columnas de fecha\n",
    "df[\"appointment_date\"] = pd.to_datetime(df[\"appointment_date\"], errors=\"coerce\")\n",
    "df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], errors=\"coerce\")\n",
    "\n",
    "# Validar conversiones\n",
    "print(\"Fechas inválidas (appointment_date):\", df[\"appointment_date\"].isna().sum())\n",
    "print(\"Fechas inválidas (signup_date):\", df[\"signup_date\"].isna().sum())\n",
    "\n",
    "df[[\"appointment_date\",\"signup_date\"]].describe(datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 · Construir métricas por cliente (base para análisis y segmentación)\n",
    "\n",
    "En la práctica, la segmentación suele hacerse con variables agregadas.  \n",
    "Vamos a construir un dataframe de métricas por cliente, por ejemplo:\n",
    "\n",
    "- `num_visits`: número de citas\n",
    "- `total_spend`: gasto total (solo ingresos, excluyendo reembolsos)\n",
    "- `refund_count` y `refund_rate`\n",
    "- `avg_ticket` y `max_ticket`\n",
    "- `last_visit_date` y `recency_days` (días desde la última cita)\n",
    "- KPIs operativos: `avg_wait_time`, `avg_duration`, `avg_satisfaction`\n",
    "\n",
    "**Nota:** aquí aplicamos `groupby` + `agg`, que es una habilidad esencial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Métricas por cliente (agregación)\n",
    "# ============================================================\n",
    "\n",
    "# Separar ingresos vs reembolsos\n",
    "df[\"is_refund\"] = df[\"is_refund\"].astype(int)\n",
    "\n",
    "df_revenue = df[df[\"amount_net\"] > 0].copy()\n",
    "df_refunds = df[df[\"amount_net\"] < 0].copy()\n",
    "\n",
    "print(\"Ingresos:\", len(df_revenue), \"| Reembolsos:\", len(df_refunds))\n",
    "\n",
    "# Fecha de corte del análisis (simula “hoy” en un proyecto)\n",
    "as_of_date = df[\"appointment_date\"].max()\n",
    "as_of_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregación por cliente\n",
    "customer_metrics = (\n",
    "    df.groupby(\"customer_id\")\n",
    "      .agg(\n",
    "          num_visits=(\"transaction_id\",\"nunique\"),\n",
    "          total_spend=(\"amount_net\", lambda s: s[s>0].sum()),      # solo ingresos\n",
    "          refund_count=(\"is_refund\",\"sum\"),\n",
    "          avg_ticket=(\"amount_net\", lambda s: s[s>0].mean()),\n",
    "          max_ticket=(\"amount_net\", lambda s: s[s>0].max()),\n",
    "          last_visit_date=(\"appointment_date\",\"max\"),\n",
    "          avg_wait_time=(\"wait_time_min\",\"mean\"),\n",
    "          avg_duration=(\"service_duration_min\",\"mean\"),\n",
    "          avg_satisfaction=(\"satisfaction_score\",\"mean\"),\n",
    "          city=(\"city\",\"first\"),\n",
    "          plan=(\"plan\",\"first\"),\n",
    "          acquisition_channel=(\"acquisition_channel\",\"first\"),\n",
    "          age=(\"age\",\"first\"),\n",
    "          has_insurance=(\"has_insurance\",\"first\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Recency en días\n",
    "customer_metrics[\"recency_days\"] = (as_of_date - customer_metrics[\"last_visit_date\"]).dt.days\n",
    "\n",
    "# Refund rate (por visitas)\n",
    "customer_metrics[\"refund_rate\"] = customer_metrics[\"refund_count\"] / customer_metrics[\"num_visits\"]\n",
    "\n",
    "display(customer_metrics.head())\n",
    "customer_metrics.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-ejercicio (5 min)\n",
    "\n",
    "1. Calcula el **percentil 90** de `total_spend` y úsalo para identificar los clientes “Top 10%”.\n",
    "2. Crea una columna `is_top_spender` (1 si está en el Top 10%, 0 si no).\n",
    "\n",
    "Pista: `customer_metrics[\"total_spend\"].quantile(0.90)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución (Mini-ejercicio)\n",
    "p90 = customer_metrics[\"total_spend\"].quantile(0.90)\n",
    "customer_metrics[\"is_top_spender\"] = (customer_metrics[\"total_spend\"] >= p90).astype(int)\n",
    "\n",
    "p90, customer_metrics[\"is_top_spender\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.1 · Identificando valores atípicos con reglas estadísticas (aplicación práctica)\n",
    "\n",
    "En el webinar teórico vimos dos reglas comunes:\n",
    "\n",
    "- **IQR (Interquartile Range):** robusto para distribuciones sesgadas (típico en montos).\n",
    "- **Z-score:** útil si la variable es aproximadamente normal (o tras transformar).\n",
    "\n",
    "En un proyecto real, esto se traduce en:\n",
    "1. Medir cuántos outliers hay.\n",
    "2. Inspeccionar ejemplos (¿errores? ¿casos reales extremos?).\n",
    "3. Decidir tratamiento (no siempre se eliminan).\n",
    "\n",
    "En este ejercicio analizaremos outliers en:\n",
    "- `amount_net` (en ingresos)\n",
    "- `wait_time_min`\n",
    "- `age` (calidad de datos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.1 A) Detección de outliers con IQR (ejemplo: total_spend)\n",
    "# ============================================================\n",
    "\n",
    "metric = \"total_spend\"\n",
    "\n",
    "q1 = customer_metrics[metric].quantile(0.25)\n",
    "q3 = customer_metrics[metric].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "customer_metrics[\"outlier_iqr_total_spend\"] = ((customer_metrics[metric] < lower) | (customer_metrics[metric] > upper)).astype(int)\n",
    "\n",
    "print(\"IQR bounds:\", lower, upper)\n",
    "customer_metrics[\"outlier_iqr_total_spend\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver ejemplos de outliers (top 10 por total_spend)\n",
    "outliers_spend = customer_metrics[customer_metrics[\"outlier_iqr_total_spend\"] == 1].sort_values(\"total_spend\", ascending=False)\n",
    "display(outliers_spend.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.1 B) Detección de outliers con Z-score (ejemplo: wait_time_min)\n",
    "# ============================================================\n",
    "\n",
    "# Para Z-score es mejor usar una variable por transacción (aquí: wait_time_min)\n",
    "wait = df[\"wait_time_min\"].dropna()\n",
    "\n",
    "mean_w = wait.mean()\n",
    "std_w = wait.std(ddof=0)\n",
    "\n",
    "z = (df[\"wait_time_min\"] - mean_w) / std_w\n",
    "df[\"outlier_z_wait_time\"] = (z.abs() > 3).astype(int)\n",
    "\n",
    "df[\"outlier_z_wait_time\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización rápida (histograma) para entender sesgo y outliers\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df_revenue[\"amount_net\"], bins=50)\n",
    "plt.title(\"Distribución de amount_net (solo ingresos)\")\n",
    "plt.xlabel(\"amount_net\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df[\"wait_time_min\"], bins=50)\n",
    "plt.title(\"Distribución de wait_time_min\")\n",
    "plt.xlabel(\"wait_time_min\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.2 · Cómo abordar valores atípicos según el contexto (aplicación práctica)\n",
    "\n",
    "Regla de oro: **outlier ≠ error**.  \n",
    "Un outlier puede ser:\n",
    "\n",
    "- Un **error de captura** (edad = 999, satisfacción = 12)\n",
    "- Un **evento real extremo** (una atención costosa)\n",
    "- Un **sub-proceso diferente** (reembolsos: valores negativos esperados)\n",
    "\n",
    "Aquí tomaremos decisiones típicas de negocio:\n",
    "\n",
    "1. **Edad**: marcar valores fuera de rango y corregir a `NaN` para no distorsionar.\n",
    "2. **Satisfacción**: forzar rango 1–10 y dejar `NaN` si es inválido.\n",
    "3. **Montos**: usar *capping* (winsorization) en p99 para análisis agregado.\n",
    "4. **Reembolsos**: NO mezclarlos como “outliers”; tratarlos como categoría separada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.2 A) Limpieza por reglas de negocio (edad y satisfacción)\n",
    "# ============================================================\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Edad válida: 18 a 90 (lo demás lo marcamos como NaN)\n",
    "df_clean[\"age_clean\"] = df_clean[\"age\"].where(df_clean[\"age\"].between(18, 90), np.nan)\n",
    "\n",
    "# Satisfacción válida: 1 a 10 (lo demás NaN)\n",
    "df_clean[\"satisfaction_clean\"] = df_clean[\"satisfaction_score\"].where(df_clean[\"satisfaction_score\"].between(1, 10), np.nan)\n",
    "\n",
    "print(\"Edad inválida:\", df_clean[\"age_clean\"].isna().sum(), \"de\", len(df_clean))\n",
    "print(\"Satisfacción inválida:\", df_clean[\"satisfaction_clean\"].isna().sum(), \"de\", len(df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.2 B) Capping de montos para análisis (p99 sobre ingresos)\n",
    "# ============================================================\n",
    "\n",
    "p99 = df_clean.loc[df_clean[\"amount_net\"] > 0, \"amount_net\"].quantile(0.99)\n",
    "\n",
    "df_clean[\"amount_net_capped\"] = df_clean[\"amount_net\"].copy()\n",
    "\n",
    "# Solo capear ingresos (no tocar reembolsos)\n",
    "mask_revenue = df_clean[\"amount_net_capped\"] > 0\n",
    "df_clean.loc[mask_revenue, \"amount_net_capped\"] = df_clean.loc[mask_revenue, \"amount_net_capped\"].clip(upper=p99)\n",
    "\n",
    "print(\"p99 amount_net (ingresos):\", p99)\n",
    "df_clean.loc[mask_revenue, [\"amount_net\",\"amount_net_capped\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar distribución antes/después (ingresos)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df_clean.loc[mask_revenue, \"amount_net\"], bins=50)\n",
    "plt.title(\"amount_net (antes) - solo ingresos\")\n",
    "plt.xlabel(\"amount_net\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(df_clean.loc[mask_revenue, \"amount_net_capped\"], bins=50)\n",
    "plt.title(\"amount_net_capped (después) - solo ingresos\")\n",
    "plt.xlabel(\"amount_net_capped\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.3 · Segmentación de clientes con sentencias `if/elif/else` (proyecto)\n",
    "\n",
    "Vamos a crear una segmentación simple tipo RFM:\n",
    "\n",
    "- **Recency** (días desde la última visita)\n",
    "- **Frequency** (num_visits)\n",
    "- **Monetary** (total_spend)\n",
    "\n",
    "Objetivo: producir una columna `segment_if` con categorías accionables:\n",
    "- `VIP`\n",
    "- `Leal`\n",
    "- `Prometedor`\n",
    "- `En riesgo`\n",
    "- `Bajo valor`\n",
    "\n",
    "Regla importante: la segmentación debe ser **explicable** y **reproducible**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.3 Segmentación con if/elif/else\n",
    "# ============================================================\n",
    "\n",
    "# Reconstruimos métricas usando df_clean (para usar montos cappeados si queremos)\n",
    "df_rev_clean = df_clean[df_clean[\"amount_net_capped\"] > 0].copy()\n",
    "\n",
    "as_of_date = df_clean[\"appointment_date\"].max()\n",
    "\n",
    "customer_metrics2 = (\n",
    "    df_clean.groupby(\"customer_id\")\n",
    "      .agg(\n",
    "          num_visits=(\"transaction_id\",\"nunique\"),\n",
    "          total_spend=(\"amount_net_capped\", lambda s: s[s>0].sum()),\n",
    "          last_visit_date=(\"appointment_date\",\"max\"),\n",
    "          avg_satisfaction=(\"satisfaction_clean\",\"mean\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "customer_metrics2[\"recency_days\"] = (as_of_date - customer_metrics2[\"last_visit_date\"]).dt.days\n",
    "\n",
    "# Umbrales simples (pueden ajustarse)\n",
    "p75_spend = customer_metrics2[\"total_spend\"].quantile(0.75)\n",
    "p75_visits = customer_metrics2[\"num_visits\"].quantile(0.75)\n",
    "\n",
    "def segment_customer_if(row: pd.Series) -> str:\n",
    "    \"\"\"Asigna un segmento basado en reglas RFM sencillas.\n",
    "\n",
    "    Nota pedagógica: se usa if/elif/else para que sea claro y fácil de explicar.\n",
    "    \"\"\"\n",
    "    recency = row[\"recency_days\"]\n",
    "    freq = row[\"num_visits\"]\n",
    "    monetary = row[\"total_spend\"]\n",
    "    sat = row[\"avg_satisfaction\"]\n",
    "\n",
    "    # VIP: reciente, frecuente y alto gasto\n",
    "    if (recency <= 30) and (freq >= p75_visits) and (monetary >= p75_spend):\n",
    "        return \"VIP\"\n",
    "\n",
    "    # Leal: frecuente y relativamente reciente\n",
    "    elif (recency <= 60) and (freq >= p75_visits):\n",
    "        return \"Leal\"\n",
    "\n",
    "    # Prometedor: reciente pero con menos frecuencia (o gasto moderado)\n",
    "    elif (recency <= 30) and (freq < p75_visits):\n",
    "        return \"Prometedor\"\n",
    "\n",
    "    # En riesgo: no ha venido hace tiempo pero antes tuvo actividad\n",
    "    elif (recency > 90) and (freq >= 3):\n",
    "        return \"En riesgo\"\n",
    "\n",
    "    # Bajo valor: poca frecuencia y poco gasto\n",
    "    else:\n",
    "        return \"Bajo valor\"\n",
    "\n",
    "customer_metrics2[\"segment_if\"] = customer_metrics2.apply(segment_customer_if, axis=1)\n",
    "\n",
    "customer_metrics2[\"segment_if\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.4 · Segmentación con `apply()` y funciones que integran IF para crear nuevas columnas\n",
    "\n",
    "En proyectos reales, el “segmento” no es lo único que necesitamos.  \n",
    "Frecuentemente creamos **múltiples variables** para activar acciones:\n",
    "\n",
    "- `needs_follow_up` (¿requiere seguimiento?)\n",
    "- `discount_eligible` (¿es elegible a incentivo?)\n",
    "- `recommended_channel` (¿por dónde contactarlo?)\n",
    "\n",
    "Vamos a construir una función que retorna un `pd.Series` con varias columnas nuevas y la aplicaremos con `apply()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.4 apply() para crear varias columnas\n",
    "# ============================================================\n",
    "\n",
    "def enrichment_rules(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"Reglas de enriquecimiento (múltiples flags) basadas en condiciones.\n",
    "\n",
    "    Retorna un pd.Series con varias columnas:\n",
    "    - needs_follow_up\n",
    "    - discount_eligible\n",
    "    - recommended_channel\n",
    "    \"\"\"\n",
    "    recency = row[\"recency_days\"]\n",
    "    seg = row[\"segment_if\"]\n",
    "    sat = row[\"avg_satisfaction\"]\n",
    "\n",
    "    # 1) needs_follow_up: alto recency o satisfacción baja\n",
    "    if (recency > 90) or (pd.notna(sat) and sat <= 6):\n",
    "        needs_follow_up = 1\n",
    "    else:\n",
    "        needs_follow_up = 0\n",
    "\n",
    "    # 2) discount_eligible: segmento “En riesgo” o “Bajo valor” con cierta actividad\n",
    "    if seg in [\"En riesgo\", \"Bajo valor\"] and row[\"num_visits\"] >= 2:\n",
    "        discount_eligible = 1\n",
    "    else:\n",
    "        discount_eligible = 0\n",
    "\n",
    "    # 3) recommended_channel: por defecto Email, pero si recency muy alto -> Call Center\n",
    "    if recency > 120:\n",
    "        recommended_channel = \"Call Center\"\n",
    "    else:\n",
    "        recommended_channel = \"Email\"\n",
    "\n",
    "    return pd.Series({\n",
    "        \"needs_follow_up\": needs_follow_up,\n",
    "        \"discount_eligible\": discount_eligible,\n",
    "        \"recommended_channel\": recommended_channel\n",
    "    })\n",
    "\n",
    "enriched = customer_metrics2.apply(enrichment_rules, axis=1)\n",
    "customer_metrics2 = pd.concat([customer_metrics2, enriched], axis=1)\n",
    "\n",
    "display(customer_metrics2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-ejercicio (5 min)\n",
    "\n",
    "1. Crea una columna `priority` con estos valores:\n",
    "   - `Alta` si `needs_follow_up == 1` y `discount_eligible == 1`\n",
    "   - `Media` si `needs_follow_up == 1` y `discount_eligible == 0`\n",
    "   - `Baja` en cualquier otro caso\n",
    "\n",
    "Hazlo de dos maneras:\n",
    "- (A) con `if/elif/else` en una función\n",
    "- (B) con `np.select`\n",
    "\n",
    "Compara cuál te parece más legible para un equipo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución (Mini-ejercicio)\n",
    "\n",
    "def priority_if(row):\n",
    "    if (row[\"needs_follow_up\"] == 1) and (row[\"discount_eligible\"] == 1):\n",
    "        return \"Alta\"\n",
    "    elif (row[\"needs_follow_up\"] == 1) and (row[\"discount_eligible\"] == 0):\n",
    "        return \"Media\"\n",
    "    else:\n",
    "        return \"Baja\"\n",
    "\n",
    "customer_metrics2[\"priority_if\"] = customer_metrics2.apply(priority_if, axis=1)\n",
    "\n",
    "conditions = [\n",
    "    (customer_metrics2[\"needs_follow_up\"] == 1) & (customer_metrics2[\"discount_eligible\"] == 1),\n",
    "    (customer_metrics2[\"needs_follow_up\"] == 1) & (customer_metrics2[\"discount_eligible\"] == 0),\n",
    "]\n",
    "choices = [\"Alta\", \"Media\"]\n",
    "\n",
    "customer_metrics2[\"priority_npselect\"] = np.select(conditions, choices, default=\"Baja\")\n",
    "\n",
    "customer_metrics2[[\"priority_if\",\"priority_npselect\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.5 · Redacción de un Statistical Summary (proyecto)\n",
    "\n",
    "Un Statistical Summary es un texto corto (1–2 páginas) que:\n",
    "\n",
    "1. Resume el dataset (tamaño, cobertura temporal).\n",
    "2. Describe hallazgos clave (KPIs, distribuciones).\n",
    "3. Documenta decisiones (tratamiento de outliers, supuestos).\n",
    "4. Entrega conclusiones y próximos pasos.\n",
    "\n",
    "Aquí crearemos una **plantilla automática** que toma métricas calculadas y genera un borrador en Markdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.3.5 Generar un Statistical Summary en Markdown\n",
    "# ============================================================\n",
    "\n",
    "# KPIs globales\n",
    "n_rows = len(df_clean)\n",
    "n_customers = df_clean[\"customer_id\"].nunique()\n",
    "\n",
    "date_min = df_clean[\"appointment_date\"].min().date()\n",
    "date_max = df_clean[\"appointment_date\"].max().date()\n",
    "\n",
    "refund_rate_global = (df_clean[\"amount_net\"] < 0).mean()\n",
    "avg_ticket_global = df_clean.loc[df_clean[\"amount_net_capped\"] > 0, \"amount_net_capped\"].mean()\n",
    "\n",
    "# Distribución de segmentos\n",
    "segment_dist = customer_metrics2[\"segment_if\"].value_counts(normalize=True).round(4)\n",
    "\n",
    "summary_md = f\"\"\"# Statistical Summary · Clínica Agendada\n",
    "\n",
    "## 1. Dataset\n",
    "- Filas (transacciones/citas): **{n_rows:,}**\n",
    "- Clientes únicos: **{n_customers:,}**\n",
    "- Ventana temporal: **{date_min} → {date_max}**\n",
    "\n",
    "## 2. Calidad y preparación\n",
    "- Se crearon columnas limpias:\n",
    "  - `age_clean` (edad válida 18–90; inválidos a NaN)\n",
    "  - `satisfaction_clean` (rango 1–10; inválidos a NaN)\n",
    "- Para análisis de montos, se aplicó *capping* en p99 sobre ingresos (no reembolsos):\n",
    "  - `amount_net_capped`\n",
    "\n",
    "## 3. Hallazgos (KPIs)\n",
    "- Tasa global de reembolsos (por transacción): **{refund_rate_global:.2%}**\n",
    "- Ticket promedio (ingresos cappeados): **{avg_ticket_global:,.0f}**\n",
    "\n",
    "## 4. Segmentación (RFM simplificado)\n",
    "Distribución de segmentos (proporción de clientes):\n",
    "{segment_dist.to_string()}\n",
    "\n",
    "## 5. Recomendaciones\n",
    "- Revisar outliers de espera (`wait_time_min`) para identificar cuellos de botella.\n",
    "- Diseñar campañas por segmento:\n",
    "  - VIP: beneficios premium / cross-sell\n",
    "  - En riesgo: follow-up + incentivo controlado\n",
    "  - Bajo valor: onboarding + educación del servicio\n",
    "\n",
    "## 6. Próximos pasos\n",
    "- Validar reglas con stakeholders (operaciones, finanzas).\n",
    "- A/B test de incentivos por segmento.\n",
    "\"\"\"\n",
    "\n",
    "# Guardar el summary como artefacto de proyecto\n",
    "summary_file = OUTPUTS_DIR / \"statistical_summary.md\"\n",
    "summary_file.write_text(summary_md, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Resumen guardado en: {summary_file}\")\n",
    "print(summary_md[:600] + \"\\n...\")  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 · Almacenando y compartiendo análisis (publicación en GitHub)\n",
    "\n",
    "En un proyecto real, tu análisis debe ser:\n",
    "- **Reproducible** (otros pueden correrlo)\n",
    "- **Versionado** (historial de cambios)\n",
    "- **Compartible** (enlace a repo + README)\n",
    "\n",
    "En este bloque vamos a:\n",
    "1. Guardar artefactos (`outputs/`, `figures/`).\n",
    "2. Crear `README.md` mínimo.\n",
    "3. Inicializar repo Git, hacer commits y preparar el push a GitHub.\n",
    "4. Ver el workflow típico en Google Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.4 A) Guardar outputs del proyecto\n",
    "# ============================================================\n",
    "\n",
    "# Guardar métricas por cliente\n",
    "customer_metrics_file = OUTPUTS_DIR / \"customer_metrics.csv\"\n",
    "customer_metrics2.to_csv(customer_metrics_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Archivo guardado: {customer_metrics_file} | filas={len(customer_metrics2):,}\")\n",
    "\n",
    "# (Opcional) Guardar un gráfico como figura\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(customer_metrics2[\"total_spend\"], bins=50)\n",
    "plt.title(\"Distribución de total_spend por cliente (cappeado)\")\n",
    "plt.xlabel(\"total_spend\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "\n",
    "fig_path = FIG_DIR / \"total_spend_hist.png\"\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Figura guardada: {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.4 B) Crear README.md y (opcional) requirements.txt\n",
    "# ============================================================\n",
    "\n",
    "readme_file = Path(\"README.md\")\n",
    "if not readme_file.exists():\n",
    "    readme_file.write_text(\"\"\"# Proyecto · Clínica Agendada (Sprint 7)\n",
    "\n",
    "Este repositorio contiene un proyecto práctico de Data Analytics para:\n",
    "\n",
    "- Analizar calidad de datos y EDA\n",
    "- Detectar y tratar outliers (IQR/Z-score + contexto de negocio)\n",
    "- Construir métricas por cliente (RFM simplificado)\n",
    "- Segmentar clientes (if + apply)\n",
    "- Redactar un Statistical Summary\n",
    "\n",
    "## Estructura\n",
    "\n",
    "- `data/clinic_transactions.csv`: dataset (sintético)\n",
    "- `notebooks/`: notebook del proyecto\n",
    "- `outputs/`: métricas y summary\n",
    "- `figures/`: gráficos exportados\n",
    "\n",
    "## Cómo ejecutar\n",
    "\n",
    "1. Crear entorno (recomendado): `python -m venv .venv`\n",
    "2. Instalar dependencias: `pip install -r requirements.txt`\n",
    "3. Abrir y ejecutar el notebook.\n",
    "\n",
    "## Resultados principales\n",
    "\n",
    "Ver `outputs/statistical_summary.md`.\n",
    "\"\"\", encoding=\"utf-8\")\n",
    "    print(\"README.md creado.\")\n",
    "else:\n",
    "    print(\"README.md ya existe (no se sobreescribió).\")\n",
    "\n",
    "requirements_file = Path(\"requirements.txt\")\n",
    "if not requirements_file.exists():\n",
    "    requirements_file.write_text(\"\\n\".join([\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"matplotlib\"\n",
    "    ]) + \"\\n\", encoding=\"utf-8\")\n",
    "    print(\"requirements.txt creado.\")\n",
    "else:\n",
    "    print(\"requirements.txt ya existe (no se sobreescribió).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1–7.4.3 · GitHub para analistas + estructura de repos + workflow con Colab\n",
    "\n",
    "A continuación tienes comandos típicos para publicar tu proyecto.\n",
    "\n",
    "> Nota: estos comandos se ejecutan en terminal.  \n",
    "> En Jupyter/Colab puedes ejecutarlos con `!` al inicio.\n",
    "\n",
    "#### Paso 1: Crear estructura de repo (sugerida)\n",
    "\n",
    "```\n",
    "project/\n",
    "  data/\n",
    "  notebooks/\n",
    "  outputs/\n",
    "  figures/\n",
    "  README.md\n",
    "  requirements.txt\n",
    "  .gitignore\n",
    "```\n",
    "\n",
    "#### Paso 2: Inicializar git y primer commit\n",
    "\n",
    "```\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial commit: project skeleton + dataset + notebook\"\n",
    "```\n",
    "\n",
    "#### Paso 3: Crear repo en GitHub y agregar remote\n",
    "\n",
    "En GitHub: New repository → copia la URL (HTTPS).\n",
    "\n",
    "```\n",
    "git remote add origin https://github.com/<TU_USUARIO>/<TU_REPO>.git\n",
    "git branch -M main\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "#### Paso 4: Workflow recomendado (GitHub Flow)\n",
    "\n",
    "- Crea branch por cambio: `git checkout -b feature/segmentacion`\n",
    "- Commits pequeños y descriptivos\n",
    "- Pull Request → revisión → merge\n",
    "\n",
    "#### En Google Colab (workflow típico)\n",
    "1. Conecta Google Drive (opcional).\n",
    "2. Clona tu repo: `!git clone https://github.com/<TU_USUARIO>/<TU_REPO>.git`\n",
    "3. Ejecuta el notebook, genera outputs.\n",
    "4. Commit y push desde Colab (requiere autenticación/token).\n",
    "\n",
    "**Tip:** evita subir datos sensibles. En este proyecto el dataset es sintético, así que está OK subirlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "- La detección de outliers (IQR/Z-score) es el **inicio**, no el final: el contexto define la acción.\n",
    "- Segmentación efectiva = reglas **claras**, variables agregadas y trazabilidad.\n",
    "- Un buen Statistical Summary documenta **métricas + decisiones + supuestos**.\n",
    "- Publicar en GitHub vuelve tu análisis **reproducible** y facilita colaboración.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cierre (5 min)\n",
    "\n",
    "Checklist final del proyecto:\n",
    "\n",
    "- [ ] `data/clinic_transactions.csv` generado\n",
    "- [ ] Notebook ejecuta end-to-end sin errores\n",
    "- [ ] `outputs/customer_metrics.csv` exportado\n",
    "- [ ] `outputs/statistical_summary.md` creado\n",
    "- [ ] `figures/` contiene al menos 1 gráfico (opcional)\n",
    "- [ ] Repo publicado en GitHub con `README.md`\n",
    "\n",
    "### Preguntas para discusión\n",
    "1. ¿Qué outliers decidiste “corregir” vs “preservar”? ¿Por qué?\n",
    "2. ¿Las reglas de segmentación son razonables para negocio? ¿Qué cambiarías?\n",
    "3. ¿Qué información adicional necesitarías del stakeholder para mejorar el análisis?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
